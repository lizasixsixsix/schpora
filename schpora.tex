\documentclass[a4paper]{article}
\usepackage{fontspec}
\usepackage[14pt]{extsizes}
\usepackage[left=2.15cm,
            right=1.85cm,
            top=1.5cm,
            bottom=2.0cm,
            bindingoffset=0cm]{geometry}
\usepackage[dvipsnames]{xcolor}
\usepackage{eso-pic}
\usepackage{graphicx}
\usepackage{pgf}
\usepackage{xtab, booktabs}
\usepackage{anyfontsize}

%----            
            
\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

%----

\usepackage{parskip}

\setlength{\parskip}{2.5ex plus 0.5ex minus 0.5ex}

\usepackage{setspace}

%----

\setmainfont[
    Path = ../Fonts/cm-unicode-0.7.0/,
    Extension = .ttf,
    UprightFont = * Roman,
    ItalicFont = * Italic,
    BoldFont = * Bold Extended Roman,
    BoldItalicFont = * Bold Extended Italic,
    SlantedFont = * Roman Slanted,
    Ligatures = TeX]{CMU Serif}

\setsansfont[
    Path =../Fonts/cm-unicode-0.7.0/,
    Extension = .ttf,
    UprightFont = *,
    ItalicFont = * Oblique,
    BoldFont = * Bold Extended,
    BoldItalicFont = * Bold Extended Oblique,
    Ligatures = TeX]{CMU Sans Serif}

\setmonofont[
    Path = ../Fonts/cm-unicode-0.7.0/,
    Extension = .ttf,
    UprightFont = * Regular,
    ItalicFont = * Italic,
    BoldFont = * Bold,
    BoldItalicFont = * Bold Italic,
    Ligatures = TeX]{CMU Typewriter Text}

\newfontfamily\upit[
    Path = ../Fonts/cm-unicode-0.7.0/,
    Extension = .ttf,
    UprightFont = *,
    Ligatures = TeX]{CMU Serif Upright Italic}

\newfontfamily\conc[
    Path = ../Fonts/cm-unicode-0.7.0/,
    Extension = .ttf,
    UprightFont = * Roman,
    ItalicFont = * Italic,
    BoldFont = * Bold Extended Roman,
    BoldItalicFont = * Bold Extended Italic,
    Ligatures = TeX]{CMU Concrete}
    
\newfontfamily\amer[
    Path = ../Fonts/A. Gophmann/,
    Extension = .ttf,
    UprightFont = *,
    Ligatures = TeX]{American Retro}

%----

\usepackage{polyglossia}

\setdefaultlanguage{russian}
\setotherlanguage{english}

%----

\newcommand\BackgroundPic{%
    \put(0,0){%
        \parbox[b][\paperheight]{\paperwidth}{%
            \centering{%
                \makebox[0pt]{%
                    \pgfsetfillopacity{0.05}%
                    \includegraphics[trim = 0mm 0mm 0mm 0mm, % l b r t
                                     clip, % for trim
                                     height=\paperheight]{Images/Drops}}%
                    \pgfsetfillopacity{1.0}
            }
        }
    }
}

%----

\DeclareMathOperator{\const}{const}

\DeclareMathOperator{\expo}{exp}

\DeclareMathOperator{\cov}{Cov}

\makeatletter
\newsavebox\myboxA
\newsavebox\myboxB
\newlength\mylenA

\newcommand*\xoverline[2][0.75]{%
    \sbox{\myboxA}{$\m@th#2$}%
    \setbox\myboxB\null% Phantom box
    \ht\myboxB=\ht\myboxA%
    \dp\myboxB=\dp\myboxA%
    \wd\myboxB=#1\wd\myboxA% Scale phantom
    \sbox\myboxB{$\m@th\overline{\copy\myboxB}$}%  Overlined phantom
    \setlength\mylenA{\the\wd\myboxA}% calc width diff
    \addtolength\mylenA{-\the\wd\myboxB}%
    \ifdim\wd\myboxB<\wd\myboxA%
       \rlap{\hskip 0.5\mylenA\usebox\myboxB}{\usebox\myboxA}%
    \else
        \hskip -0.5\mylenA\rlap{\usebox\myboxA}{\hskip 0.5\mylenA\usebox\myboxB}%
    \fi}
\makeatother

\newcommand{\nix}[1]{\xoverline{#1}}
\newcommand{\nixx}[1]{\xoverline[0.875]{#1}}

\newcommand{\rep}[1]{\widehat{#1}}

\newcommand{\none}{\varnothing}

\newcommand{\sleq}{\leqslant}
\newcommand{\sgeq}{\geqslant}

\newcommand{\sqrtt}[1]{\sqrt{\vphantom{qb} #1}}

%----

\renewcommand{\qedsymbol}{\ensuremath{\blacksquare}}

\newcommand{\qeddnostar}{\hfill{\color{Dark}\qedsymbol}}

\newcommand{\qeddstar}[1]{\hfill{\color{Dark}\raisebox{#1}{\qedsymbol}}}

\makeatletter
\newcommand\qedd{\@ifstar\qeddstar\qeddnostar}
\makeatother

%----

\usepackage{caption}

\captionsetup[figure]{position=bottom, font=small, skip=18pt}

\captionsetup[table]{position=top, font=small, skip=8pt}

\captionsetup[lstlisting]{position=top, font=small, skip=8pt}

\setlength{\belowcaptionskip}{1.5ex} % space between caption and text

%----

\setlength{\intextsep}{5.0ex plus 0.5ex minus 0.5ex}    % between float and text if [h]
\setlength{\textfloatsep}{5.0ex plus 0.5ex minus 0.5ex} % between float and text if not [h]
\setlength{\floatsep}{5.0ex plus 0.5ex minus 0.5ex}     % between floats

%----

\usepackage{array, ragged2e}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}

\renewcommand{\arraystretch}{1.25}

\newcommand{\cen}[1]{\Centering #1}

%----

\usepackage{longtable}

%----

\usepackage{hyperref}

\hypersetup{
    unicode,
    pdfdisplaydoctitle,
    pdftitle={---},
    pdfauthor={Me},
    colorlinks=true
}

%----

\usepackage{bookmark}

\bookmarksetup{
    open,
    openlevel=2,
    depth=4,
    numbered,
    addtohook={%
        \ifnum\bookmarkget{level}=1
            \bookmarksetup{bold,color=Dark}%
        \fi
        \ifnum\bookmarkget{level}=2
            \bookmarksetup{italic,bold,color=Medium}%
        \fi
        \ifnum\bookmarkget{level}=3
            \bookmarksetup{color=Light}%
        \fi
        \ifnum\bookmarkget{level}=4
            \bookmarksetup{italic,color=Medium}%
        \fi
    }
}

%----

\definecolor{Dark}{HTML}{00A3E3}
\definecolor{Medium}{HTML}{F9281D}
\definecolor{Light}{HTML}{00B3AD}

%----

\usepackage[explicit]{titlesec}

\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{\arabic{subsection}.}
\renewcommand{\thesubsubsection}{}

\titleformat{\section}{\Huge\amer\color{Dark}}{\thesection}{0.0em}{#1}
\titleformat{\subsection}{\large\sffamily\bfseries\color{Medium}}{\thesubsection}{0.5em}{#1}
\titleformat{\subsubsection}{\sffamily\bfseries\color{Light}}{\thesubsubsection}{0.0em}{#1}

\titleformat{\paragraph}[hang]{\sffamily\color{Medium}}{\theparagraph}{0.0em}{#1}
\titlespacing*{\paragraph}{0pt}{1.5ex plus 0.5ex minus 0.2ex}{-0.0ex}

\titleformat{\subparagraph}[hang]{\sffamily\itshape\color{Light}}{\thesubparagraph}{0.0em}{#1}
\titlespacing*{\subparagraph}{0pt}{0.0ex plus 0.1ex minus 0.1ex}{-0.5ex}

%----

\usepackage[nottoc]{tocbibind}

%----

\usepackage{tocloft}

\setcounter{tocdepth}{1}

\cftsetindents{section}{0.0em}{0.0em}
\cftsetindents{subsection}{2.4em}{1.2em}
\cftsetindents{subsubsection}{4.8em}{2.0em} % {<entry>}{<indent>}{<numwidth>}

\renewcommand\cfttoctitlefont{\Huge\amer\color{Dark}}

\renewcommand\cftaftertoctitleskip{4.0ex}

\renewcommand\cftsecafterpnum{\vspace{1.0ex}}
\renewcommand\cftsubsecafterpnum{\vspace{0.5ex}}
\renewcommand\cftsubsubsecafterpnum{\vspace{0.5ex}}

\renewcommand\cftsecfont{\normalfont}
\renewcommand\cftsubsecfont{\normalfont}
\renewcommand\cftsubsubsecfont{\normalfont}

\renewcommand\cftsecpagefont{\normalfont\color{Medium}}
\renewcommand\cftsubsecpagefont{\normalfont\color{Medium}}
\renewcommand\cftsubsubsecpagefont{\normalfont\color{Medium}}

\renewcommand\cftsecdotsep{\cftdotsep}

\renewcommand\cftsecleader{\normalsize\color{Medium}\cftdotfill{\cftsecdotsep}}
\renewcommand\cftsubsecleader{\normalsize\color{Medium}\cftdotfill{\cftsubsecdotsep}}
\renewcommand\cftsubsubsecleader{\normalsize\color{Medium}\cftdotfill{\cftsubsubsecdotsep}}

%----

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[R]{\mdseries\small\thepage}
\renewcommand{\headrulewidth}{0pt}

\fancypagestyle{plain}{% redefine 'plain' pagestyle (for roman-numbered pages)
    \fancyhf{} % clear all header and footer fields
    \fancyfoot[L]{\mdseries\small\thepage} % except the center
    \renewcommand{\headrulewidth}{0pt}
}

%----

\usepackage{pgfplots}

\pgfplotsset{compat=1.14}

%----

\usetikzlibrary{arrows.meta}

%----

\usepgfplotslibrary{fillbetween}

%----

\usetikzlibrary{calc}

\def\centerarc[#1](#2)(#3:#4:#5)% Syntax: [draw options] (center) (initial angle:final angle:radius)
    {\draw[#1] ($(#2)+({#5*cos(#3)},{#5*sin(#3)})$) arc (#3:#4:#5);}

%----

\usepackage{placeins}

%----

\renewcommand\labelitemi{{\color{Light}$\bullet$}}
\renewcommand\labelitemii{{\color{Medium}$\bullet$}}

\renewcommand\labelenumi{{\color{Light}\bfseries\arabic{enumi}.}}
\renewcommand\labelenumii{{\color{Medium}\bfseries\arabic{enumi}.}}

%----

\usepackage{icomma}

\usepackage{siunitx}

\sisetup{output-decimal-marker={,}}

\usepackage{xfrac}

\usepackage{commath}

%----

\newcommand{\key}[1]{{\color{Medium}\bfseries #1}}

\newcommand{\note}{{\color{Dark}\bfseries {\Large !} Замечание: \newline}}

\newcommand{\prooff}{{\color{Dark}\bfseries Доказательство: \newline}}

\newcommand{\theorr}{{\color{Medium}\bfseries Теорема: \newline}}

%----end of preambula----

\begin{document}
    \pgfsetfillopacity{0.05}
    \AddToShipoutPicture{\BackgroundPic}
    \pgfsetfillopacity{1.0}
    
    %\pagenumbering{gobble}
    
    \disablehyphenation

    \raggedright

    \section{Теория вероятностей}

        \subsection{Основные понятия}

            \subsubsection{Предмет изучения}

                \key{Теория вероятностей} --- математическая наука, изучающая закономерности в случайных явлениях.

                \key{Событие} --- любой факт, который в результате опыта может произойти или не произойти.

                \key{Вероятность события} --- число, характеризующее степень объективной возможности появления этого события.

            \subsubsection{Теоретико-множественный подход}

                \key{Теоретико-множественный} подход к построению теории вероятностей --- современный аксиоматический подход, опирающийся на элементарные понятия теории множеств.

                \key{Пространство элементарных событий \boldmath$\Omega$} --- множество всех возможных исходов некоторого опыта со случайным исходом:

                \key{Элементарное событие \boldmath$\omega$} --- каждый элемент множества всех возможных исходов некоторого опыта со случайным исходом:
                %
                \begin{equation*}
                    \omega \in \Omega .
                \end{equation*}
                %                
                \key{Событие \boldmath$A$} --- некоторое подмножество множества всех возможных исходов некоторого опыта со случайным исходом:
                %
                \begin{equation*}
                    A \in \Omega .
                \end{equation*}
                %
                \key{Достоверное} событие --- которое происходит в каждом опыте.

                \key{Невозможное} событие --- которое в результате опыта произойти не может.

                \key{Несовместные} события --- которые в одном опыте не могут произойти одновременно.

                \key{Сумма (объединение)} двух событий $A$ и $B$ ($A + B$, $A \cup B$) --- такое событие, которое заключается в том, что происходит хотя бы одно из событий, то есть или $A$, или $B$, или оба одновременно.

                \key{Произведение (пересечение)} двух событий $A$ и $B$ ($A \cdot B$, $A \cap B$) --- такое событие, которое заключается в том, что происходят оба события $A$ и $B$ вместе.

                \key{Противоположное} к событию $A$ --- такое событие, которое заключается в том, что событие $A$ не происходит.

                \key{Полную группу} образуют события $A_k , \: k = 1 , \: 2 , \: \ldots , \: n$, если они попарно несовместны и в сумме образуют достоверное событие.

            \subsubsection{Тождества}

                \begin{equation*}
                    \begin{aligned}
                        & A + \nix{A} = \Omega ; \qquad
                            && A \cdot \nix{A} = \none ; \\[1.0ex]
                        & A + \Omega = \Omega ; \qquad
                            && A \cdot \Omega = A ; \\[1.0ex]
                        & A + \none = A ; \qquad
                            && A \cdot \none = \none ; \\[1.0ex]
                        & \nixx{A + B} = \nix{A} \cdot \nix{B} ; \qquad
                            && \nixx{A \cdot B} = \nix{A} + \nix{B} ; \\[1.0ex]
                        & A + \nix{A} \cdot B = A + B .
                    \end{aligned}
                \end{equation*}

            \subsubsection{Аксиомы}

                Пусть каждому событию $A$ ставится в соответствие число $P(A)$, называемое вероятностью события. Так как событие --- множество, то вероятность события --- функция множества. Вероятности событий удовлетворяют следующим аксиомам:
                \begin{enumerate}
                    \item Вероятность любого события заключена между нулем и единицей:
                    %
                    \begin{equation*}
                        0 \leqslant P(A) \leqslant 1 .
                    \end{equation*}
                        
                    \item Если $A$ и $B$ несовместные события, то
                    %
                    \begin{equation*}
                        P(A + B) = P(A) + P(B) .
                    \end{equation*}
                    %
                    Эта аксиома обобщается на любое количество событий, если все они попарно несовместны.
                \end{enumerate}

            \subsubsection{Случаи}

                \key{Равновозможными} называются события $A_1 , \: A_2 , \: \ldots , \: A_n$ такие, что
                %
                \begin{equation*}
                    P(A_1) = P(A_2) = \ldots = P(A_n) .
                \end{equation*}
                
                Если в каком-то опыте пространство элементарных событий $\Omega$ можно представить в виде полной группы несовместных и равновозможных событий $\omega_1 , \: \omega_2 , \: \ldots , \: \omega_n$, то такие события называются \key{случаями}, а сам опыт сводится к \key{схеме случаев}.

                Случай $\omega_i$ называется благоприятным событию $A$, если он является элементом множества $A$:
                %
                \begin{equation*}
                    \omega_i \in A .
                \end{equation*}

            \subsubsection{Определения вероятности}

                \key{Классическое определение вероятности:} \newline                
                вероятность события определяется по формуле
                %
                \begin{equation*}
                    P(A) = \frac{m}{n} ,
                \end{equation*}
                %
                где \newline
                $n$ --- число элементарных равновозможных исходов данного опыта; \newline
                $m$ --- число равновозможных исходов, приводящих к появлению события.

                \key{Геометрическое определение вероятности:}

                \begin{tikzpicture}
                    \draw [gray!12!white, line width=4pt, fill=white, fill opacity=0.75]
                        (0.0, 0.0) ellipse (3.0cm and 1.5cm);
                    \draw [yellow!95!red, line width=4pt, fill=yellow, fill opacity=0.5]
                        (-0.8, 0.0) ellipse (1.5cm and 0.85cm);
                    \filldraw [Medium] (1.05, 0.45) circle (2pt)
                        node [anchor=south west] {$T$};
                    \node [Medium] at (1.8, 0.0) {$\Omega$};
                    \node [Medium] at (-0.8, 0.0) {$A$};
                \end{tikzpicture}

                Пусть в некоторую область $\Omega$ случайным образом бросается точка $T$, причем все точки области равноправны в отношении попадания точки $T$. Тогда за вероятность попадания точки $T$ в область $A$ принимается отношение
                %
                \begin{equation*}
                    P(A) = \frac{S(A)}{S(\Omega)} ,
                \end{equation*}
                %
                где $S(A)$ и $S(\Omega)$ --- геометрические меры областей $A$ и $\Omega$ соответственно.

            \subsubsection{Выборки}

                Пусть имеется множество $X = \{ x_1 , \: x_2 , \: \ldots , \: x_n \}$, состоящее из $n$ различных элементов.

                \key{\boldmath$(n, \: r)$-выборка} --- множество, состоящее из $r$ элементов, взятых из множества $X$.

                \key{Упорядоченная} выборка --- для которой важен порядок следования элементов.

                Выборка \key{с повторениями} --- если каждый элемент множества $X$ может извлекаться несколько раз.

                \key{Перестановка} --- упорядоченная $(n, \: r)$-выборка.

                \key{Сочетание} --- неупорядоченная $(n, \: r)$-выборка.

            \subsubsection{Основные комбинаторные формулы}

                Число перестановок с повторениями $\rep{P }^r_n$ равно
                %
                \begin{equation*}
                    \rep{P }^r_n = n^r ,
                \end{equation*}
                
                Число перестановок без повторений $P ^r_n$ равно
                %
                \begin{equation*}
                    P ^r_n = \frac{n!}{(n - r)!} ,
                \end{equation*}

                Число сочетаний с повторениями $\rep{C}^r_n$ равно
                %
                \begin{equation*}
                    \rep{C}^r_n = \frac{(n + r - 1)!}{r! (n - r)!} ,
                \end{equation*}

                Число сочетаний без повторений $C^r_n$ равно
                %
                \begin{equation*}
                    C^r_n = \frac{n!}{r! (n - r)!} ,
                \end{equation*}

                Число различных \key{разбиений} множества из $n$ элементов на $k$ непересекающихся подмножеств, причем в 1-м подмножестве $r_1$ элементов, во 2-м --- $r_2$ элементов и так далее, а $n = равно r_1 , \: r_2 , \: \ldots , \: r_n $:
                %
                \begin{equation*}
                    P_n(r_1 , \: r_2 , \: \ldots , r_n) = \frac{n!}{r_1! r_2! \ldots r_n!} ,
                \end{equation*}

        \newpage
        
        \subsection{Основные теоремы}

            \subsubsection{Правило сложения вероятностей}

                Если имеется счётное множество несовместных событий $A_1 , \: A_2 , \: \ldots , \: A_n$, то
                %
                \begin{equation*}
                    P \bigg( \bigcup^{n}_{i = 1} A \bigg) = P \sum\limits_{i = 1}^{n} (A_i) .
                \end{equation*}

                Из правила сложения вероятностей вытекает, что если события $A_1 , \: A_2 , \: \ldots , \: A_n$ несовместны и образуют полную группу, то сумма их вероятностей равна единице. То есть если
                %
                \begin{equation*}
                    \sum\limits_{i = 1}^{n} (A_i) = \Omega , \quad
                        A_i \cdot A_j = \none, \: i \neq j ,
                \end{equation*}
                %
                то
                %
                \begin{equation*}
                    P \bigg( \sum\limits_{i = 1}^{n} A \bigg) =
                        P \sum\limits_{i = 1}^{n} (A_i) = P(\Omega) = 1 .
                \end{equation*}

                В частности, если два события $A$ и $\nix{A}$ противоположны, то они образуют полную группу несовместных событий и
                %
                \begin{equation*}
                    P(A) + P(\nix{A}) = 1 .
                \end{equation*}

                Тогда
                %
                \begin{equation*}
                    P(A) = 1 - P(\nix{A}) .
                \end{equation*}

                Вероятность суммы двух совместных событий равна сумме вероятностей каждого из событий минус вероятность их совместного появления:
                %
                \begin{equation*}
                    P(A \cup B) = P(A) + P(B) - P(A \cap B) .
                \end{equation*}

                Вероятность суммы трёх совместных событий:
                %
                \begin{equation*}
                    \begin{aligned}
                        P(A \cup B \cup C) = &~ P(A) + P(B) + P(C) \\[1.0ex]
                        & - P(A \cap B) - P(B \cap C) - P(A \cap C) \\[1.0ex]
                        & + P(A \cap B \cap C) .
                    \end{aligned}
                \end{equation*}

            \subsubsection{Условная вероятность}

                Событие $B$ называется \key{независимым от} события $A$, если возможность наступления события $B$ не зависит от того, произошло событие $A$ или нет, то есть:
                %
                \begin{equation*}
                    P(B | A) = P(B) .
                \end{equation*}

                В противном случае события являются \key{зависимыми}.

                \key{Условной вероятностью} события $B$ при наличии $A$ называется величина
                %
                \begin{equation*}
                    P(B | A) = \frac{P(A \cap B)}{P(A)} , \quad P(A) \neq 0 .
                \end{equation*}

                Условную вероятность события $P(B | A)$ можно трактовать как вероятность события $B$, вычисленную при условии, что событие $A$ произошло.

            \subsubsection{Правило умножения вероятностей}

                \key{Правило умножения вероятностей двух зависимых событий} \newline
                Вероятность произведения (пересечения, совмещения) двух событий равна вероятности одного из них, умноженной на условную вероятность второго при наличии первого:
                %
                \begin{equation*}
                    P(A \cap B) = P(A) P(B | A) = P(B) P(A | B) .
                \end{equation*}

                Для независимых событий правило произведения вероятностей принимает вид
                %
                \begin{equation*}
                    P(A \cap B) = P(A) P(B) .
                \end{equation*}

                Несколько событий $A_1 , \: A_2 , \: \ldots , \: A_n$ называются \key{независимыми}, если любое из них не зависит от любой комбинации (произведения) любого числа других.
                
                \key{Правило умножения вероятностей независимых событий:} \newline
                вероятность произведения нескольких независимых событий равна произведению вероятностей этих событий:
                %
                \begin{equation*}
                    P(A_1 \cap A_2 \cap \ldots \cap A_n) =
                        P(A_1) \cdot P(A_2) \cdot \ldots \cdot P(A_n) ,
                \end{equation*}
                %
                или
                %
                \begin{equation*}
                    P \bigg( \prod\limits_{i = 1}^{n} A_i \bigg) = \prod\limits_{i = 1}^{n} P(A_i) .
                \end{equation*}

                \note
                если имеется несколько событий $A_1 , \: A_2 , \: \ldots , \: A_n$, то их попарная независимость (независимость любых двух событий $A_i \text{ и } A_j , \: i \neq j$) ещё не означает их независимости в совокупности.

            \subsubsection{Формула полной вероятности}

                Формула полной вероятности является следствием основных правил теории вероятностей: теорем сложения и умножения вероятностей.

                Допустим, что проводится некоторый опыт, об условиях которого можно сделать $n$ исключающих друг друга предположений --- \key{гипотез}:
                %
                \begin{equation*}
                    \{ H_1 , \: H_2 , \: \ldots , \: H_n \} , \quad H_i \neq H_j , \: i \neq j .
                \end{equation*}

                Каждая гипотеза осуществляется случайным образом и представляет собой некоторые события, вероятности которых известны:
                %
                \begin{equation*}
                    P(H_1) ; \: P(H_2) ; \: \ldots ; \: P(H_n) .
                \end{equation*}

                Рассматривается некоторое событие $A$, которое может появиться только совместно с одной из гипотез.
                
                Заданы условные вероятности события $A$ при каждой из гипотез:
                %
                \begin{equation*}
                    P(A | H_1) ; \: P(A | H_2) ; \: \ldots ; \: P(A | H_n) .
                \end{equation*}

                Требуется найти вероятность события $A$.
                
                Для этого представим событие $A$ как сумму $n$ несовместных событий:
                %
                \begin{equation*}
                    A = (A \cap H_1) \cup (A \cap H_2) \cup \ldots \cup (A \cap H_n) .
                \end{equation*}

                По правилу сложения вероятностей
                %
                \begin{equation*}
                    P(A) = \sum\limits_{i = 1}^{n} P(H_i \cap A) .
                \end{equation*}

                По правилу умножения вероятностей
                %
                \begin{equation*}
                    P(H_i \cap A) = P(H_i) P(A | H_i) .
                \end{equation*}

                Теперь можно найти полную вероятность события $A$.

                \key{Формула полной вероятности} события $A$:
                %
                \begin{equation*}
                    P(A) = \sum\limits_{i = 1}^{n} P(H_i) P(A | H_i) ,
                \end{equation*}
                %
                то есть полная вероятность события $A$ вычисляется как сумма произведений вероятности каждой гипотезы на условную вероятность события при этой гипотезе.

                Формула полной вероятности применяется в тех случая, когда опыт со случайным исходом распадается на два этапа: на первом разыгрываются условия опыта, а на втором --- его результаты.

            \subsubsection{Формула Байеса}
                
                Следствием правила умножения и формулы полной вероятности является \key{теорема гипотез}, или \key{формула Байеса}.

                По условиям опыта известно, что гипотезы $H_1 , \: H_2 , \: \ldots , \: H_n$ несовместны и образуют полную группу событий:
                %
                \begin{equation*}
                    \begin{cases}
                        H_i \cap H_j = \none, \: i \neq j ; \\[1.0ex]
                        H_1 \cup H_2 \cup \ldots \cup H_n = \Omega .
                    \end{cases}
                \end{equation*}

                Вероятности гипотез до опыта --- \key{априорные вероятности} --- известны
                %
                \begin{equation*}
                    P(H_1) ; \: P(H_2) ; \: \ldots ; \: P(H_n)
                \end{equation*}
                %
                и равны
                %
                \begin{equation*}
                    \sum\limits_{i = 1}^{n} P(H_i) = 1 .
                \end{equation*}

                Предположим, что опыт произведен и в результате появилось событие $A$.
                
                Спрашивается, как нужно пересмотреть вероятность гипотез с учетом этого факта, или, другими словами, какова вероятность того, что наступлению события $A$ предшествовала гипотеза (\key{апостериорные вероятности} --- послеопытные):
                %
                \begin{equation*}
                    P(H_1 | A) ; \: P(H_2 | A) ; \: \ldots ; \: P(H_n | A) .
                \end{equation*}

                Вероятность наступления события $A$ совместно с гипотезой $H_k$ определяется с использованием теоремы умножения вероятностей:
                %
                \begin{equation*}
                    P(A \cap H_k) = P(H_k) P(A | H_k) = P(A) P(H_k | A) .
                \end{equation*}

                Таким образом, можно записать:
                %
                \begin{equation*}
                    P(H_k | A) = \frac{P(H_k) P(A | H_k)}{P(A)} .
                \end{equation*}

                С формулой полной вероятности получаем \key{формулу Байеса}:
                %
                \begin{equation*}
                    P(H_k | A) =
                        \frac{P(H_k) P(A | H_k)}{\sum\limits_{i = 1}^{n} P(H_i) P(A | H_i)} .
                \end{equation*}

                Формула Байеса позволяет пересчитывать вероятности гипотез в свете новой информации, состоящей в том, что опыт дал результат $A$.

            \subsubsection{Теоремы о повторении опытов}

                Несколько опытов называются \key{независимыми}, если вероятность исхода опыта не зависит от того, какие исходы имели другие опыты.
                
                Рассмотрим случай, когда вероятности исходов опытов постоянны и не зависят от номера опыта.
                
                Пусть один тот же опыт проводятся $n$ раз. В каждом опыте некоторые события $A_1 , \: A_2 , \: \ldots , \: A_r$ появляется с вероятностями $p_1 , \: p_2 , \: \ldots , \: p_r$ .
                
                Будем рассматривать не результат каждого конкретного опыта, а общее число появлений событий $A_1 , \: A_2 , \: \ldots , \: A_r$.

                \paragraph{Формула Бернулли}

                    Рассмотрим случай с двумя возможными исходами опытов, то есть в результате каждого опыта событие $A$ появляется с вероятностью $p$ и не появляется с вероятностью $q = 1 - p$.

                    Вероятность $P(n, \: k)$ того, что в последовательности из $n$ опытов интересующее нас событие произойдет ровно $k$ раз (безразлично, в какой последовательности), по \key{формуле Бернулли} равна
                    %
                    \begin{equation*}
                        P_n(k) = C_n^k p^k q^{n - k} = \frac{n!}{k!(n - k)!} p^k q^{n - k} .
                    \end{equation*}

                    Докажем это.
                    
                    Обозначим через $B_k$ появление события $A$ в $k$ опытах и появление $\nix{A}$ в $(n - k)$ опытах.
                    
                    Событие $B_k$ представляет собой сумму несовместимых событий
                    %
                    \begin{equation*}
                        \begin{aligned}
                            B_k = &~ \underbrace{A_1 \cdot A_2 \cdot \ldots
                                \cdot A_k}_{\text{\small $k$}} \cdot
                                \underbrace{\nix{A}_{k + 1} \cdot \nix{A}_{k + 2} \cdot \ldots
                                \cdot \nix{A}_n}_{\text{\small $n - k$}} \\[0.0ex]
                            & + \ldots \\[2.0ex]
                            & + \underbrace{\nix{A}_1 \cdot \nix{A}_2 \cdot \ldots
                                \cdot \nix{A}_{n - k}}_{\text{\small $n - k$}} \cdot
                                \underbrace{\nix{A}_{n - k + 1} \cdot \nix{A}_{n - k + 2} \cdot \ldots
                                \cdot \nix{A}_n}_{\text{\small $k$}} \:\: ,
                        \end{aligned}
                    \end{equation*}
                    %
                    где $A_i$ --- появление события $A$ в $i$-том опыте.

                    Определим вероятность одного из вариантов серии испытаний.
                    
                    Так как все опыты одинаковы, то вероятности всех вариантов одинаковы равны
                    %
                    \begin{equation*}
                        \begin{aligned}
                            & P(A_1 \cdot A_2 \cdot \ldots \cdot A_k \cdot
                                \nix{A}_{k + 1} \cdot \nix{A}_{k + 2} \cdot \ldots
                                \cdot \nix{A}_n) = \\[1.0ex]
                            & \underbrace{p \cdot p \cdot \ldots \cdot
                                p}_{\text{\small $k$}} \cdot
                                \underbrace{q \cdot q \cdot \ldots \cdot
                                q}_{\text{\small $n - k$}} = \\[1.0ex]
                            & p^k q^{n - k} .
                        \end{aligned}
                    \end{equation*}

                    Количество вариантов таких сложных событий равно числу выборок $k$ номеров опытов из $n$ возможных, в которых произойдут события $A$, то есть равно $C_n^k$.
                    
                    Тогда, согласно правилу сложения вероятностей для несовместных событий, $P(B_k)$ равно
                    %
                    \begin{equation*}
                        P_n(k) = P(n, \:k) = C_n^k p^k q^{n - k} . \qedd
                    \end{equation*}

                \paragraph{Следствия из формулы Бернулли}

                    Вероятность того, что в $n$ опытах схемы Бернулли событие $A$ наступит

                    \begin{itemize}
                        \item ~\ldots~ менее $k$ раз:
                        %
                        \begin{equation*}
                            P(n, \: < k) = P(n, \: 0) + P(n, \: 0) + \ldots + P(n, \: k - 1) =
                                \sum\limits_{i = 0}^{k - 1} P(n, \: i) .
                        \end{equation*}

                        \item ~\ldots~ более $k$ раз:
                        %
                        \begin{equation*}
                            P(n, \: > k) = P(n, \: k + 1) + P(n, \: k + 2) + \ldots +
                                P(n, \: n) = \sum\limits_{i = k + 1}^{n} P(n, \: i) .
                        \end{equation*}

                        \item ~\ldots~ от $k_1$ до $k_2$ раз:
                        %
                        \begin{equation*}
                            P(n, \: k_1 \sleq i \sleq k_2) = \sum\limits_{i = k_1}^{i = k_2} P(n, i) =
                                \sum\limits_{i = k_1}^{i = k_2} C_n^k p^k q^{n - k}.
                        \end{equation*}

                        \item ~\ldots~ хотя бы один раз:
                        %
                        \begin{equation*}
                            P(n, \: \sgeq 1) = P_n(1 \sleq k \sleq n) = 1 - q^n.
                        \end{equation*}
                    \end{itemize}

                    \key{Наивероятнейшее число \boldmath$k_0$} появления события $A$ --- число, которому соответствует максимальная биномиальная вероятность $P_n(k_0)$.

                    При заданных $n$ и $p$ это число определяется неравенствами
                    %
                    \begin{equation*}
                        n p - q \sleq k_0 \sleq n p + p .
                    \end{equation*}

                \paragraph{Случай с несколькими исходами опытов}

                    Пусть производится серия из n независимых опытов, в результате каждого из которых может появиться одно из событий $A_1 , \: A_2 , \: \ldots , \: A_r$ с вероятностями $p_1 , \: p_2 , \: \ldots , \: p_r$ соответственно.

                    Вероятность того, что в серии из $n$ опытов событие $A_1$ наступит ровно $k_1$ раз, событие $A_2$ --- $k_2$ раз, \ldots, событие $A_n$ --- $k_n$ раз ($k_1 + k_2 + \ldots + k_r = n$) равна
                    %
                    \begin{equation*}
                        P(n, \: k_1 , \: \ldots , \: k_r) =
                            \frac{(k_1 + \ldots + k_r)!}{k_1! \cdot \ldots! \cdot k_r!} \cdot
                            p_1^{k_1} \cdot \ldots \cdot p_r^{k_r} .
                    \end{equation*}

                \paragraph{Предельные теоремы в схеме испытаний Бернулли}

                    Вычисление вероятностей $P(n, \: k)$ при больших значениях $n$ по формуле Бернулли проблематично.
                    
                    Поэтому вычисление соответствующих вероятностей проводится с помощью приближенных формул.
                    
                    \subparagraph{Теорема Пуассона}

                        \key{Теорема Пуассона} --- предельная теорема теории вероятностей о сходимости биномиального распределения к распределению Пуассона:

                        Если $n \to \infty$ и $p \to 0$, так что $n p \to \lambda, \:\: 0 < \lambda < \infty$, то
                        %
                        \begin{equation*}
                            P_n(k) \approx \frac{\lambda^k}{k!} \cdot e^{-\lambda}, \quad
                                k = 0 , \: 1 , \: \ldots , \: n .
                        \end{equation*}

                    \subparagraph{Теоремы Муавра--Лапласа}

                        На практике приближенные формулы Муавра--Лапласа применяются в случае, когда $p$ и $q$ не малы , а $n p q > 9$.

                    \subparagraph{Локальная теорема Муавра--Лапласа}

                        Если вероятность появления события $A$ в каждом из $n, \: n \to \infty$ независимых испытаний равна одной и той же постоянной $p = \const , \: 0 < p < 1$, то вероятность того, что во всех этих испытаниях событие $A$ появится ровно $k$ раз, приближенно вычисляется формулой
                        %
                        \begin{equation*}
                            P(n, \: k) \approx \frac{1}{\sqrtt{n p q}} \cdot \varphi (x) ,
                        \end{equation*}
                        %
                        где
                        %
                        \begin{equation*}
                            x = \frac{k - n p}{\sqrtt{n p q}} ,
                        \end{equation*}
                        %
                        а
                        %
                        \begin{equation*}
                            \varphi (x) = \frac{1}{\sqrtt{2 \pi}} e^{-\frac{x^2}{2}}
                        \end{equation*}
                        %
                        --- \key{кривая Гаусса}:

                        \vspace{2.0ex}

                        \begin{tikzpicture}
                            \begin{axis}[samples=100, tick label style={font=\footnotesize}, xtick={0}, ytick={0}]
                                \addplot [Medium, thick, domain=-4.001:4]
                                    {e^(-(x^2))};
                            \end{axis}
                        \end{tikzpicture}

                        Таблицы значений функции $\varphi (x)$ даны в приложениях к учебникам по теории вероятностей.

                    \subparagraph{Интегральная теорема Муавра--Лапласа}

                        Если вероятность появления события $A$ в каждом из $n, \: n \to \infty$ независимых испытаний равна одной и той же постоянной $p = \const , \: 0 < p < 1$, то вероятность того, что во всех этих испытаниях событие $A$ появится не менее $k_1$ и не более $k_2$ раз, приближенно вычисляется формулой
                        %
                        \begin{equation*}
                            P(n, \: k_1 \sleq k \sleq k_2) \approx (\Phi (x_2) - \Phi (x_1)) ,
                        \end{equation*}
                        %
                        где
                        %
                        \begin{equation*}
                            \Phi (x) = \frac{2}{\sqrtt{2 \pi}}
                                \int\limits_{0}^{x} e^{-\frac{x^\text{\tiny 2}}{2}} \dif x
                        \end{equation*}
                        %
                        --- \key{функция Лапласа}:

                        \vspace{2.0ex}

                        \begin{tikzpicture}
                            \begin{axis}[samples=100, tick label style={font=\footnotesize}, xtick={0}, ytick distance=0.5]
                                \addplot [Medium, thick, domain=-8.001:0]
                                    {0.5 * (1 - (1 - e^x))};
                                \addplot [Medium, thick, domain=-0.001:8]
                                    {0.5 * (1 + (1 - e^(-x)))};
                            \end{axis}
                        \end{tikzpicture}

                        \begin{equation*}
                            x_1 = \frac{k_1 - n p}{\sqrtt{n p q}} , \quad
                                x_2 = \frac{k_2 - n p}{\sqrtt{n p q}} .
                        \end{equation*}
                        
                        Значения аргументов функции Лапласа для $x \in [0, \: 5]$ даны в приложениях к учебникам по теории вероятностей, для $x > 5$ \:$\Phi (x) = 1$.

        \newpage
        
        \subsection{Случайные величины}

            \subsubsection{Определение случайной величины}

                \key{Случайная величина (СВ)} --- величина, которая в результате опыта со случайным исходом принимает то или иное значение.
                
                \key{Множество \boldmath$\Xi$} --- множество возможных значений случайной величины.
                
                Обозначения случайной величины: $X$, $Y$, $Z$; \newline
                обозначения возможных значений случайной величины: $x$, $y$, $z$.

                В теоретико-множественной трактовке основных понятий теории вероятностей случайная величина $X$ --- функция элементарного события:
                %
                \begin{equation*}
                    X = \varphi (\omega_i) ,
                \end{equation*}
                %
                где $\omega_i$ --- элементарное событие, принадлежащее пространству $\Omega$.
                
                При этом множество $\Xi$ возможных значений СВ $X$ состоит из всех значений, которые принимает функция $\varphi (\omega)$.

                \paragraph{Примеры}

                    \begin{enumerate}
                        \item Опыт --- бросание двух монет. Тогда $\Xi = \{ (\text{г}, \: \text{г}) , \: (\text{г}, \: \text{ц}) , \: (\text{ц}, \: \text{г}) , \: (\text{ц}, \: \text{ц}) \}$.
                        
                        Числовая функция $X$ (СВ $X$) --- число выпадений герба, определенная на множестве $\Xi = \{ 0, \: 1, \: 2 \}$ --- герб может выпасть $0, 1, 2$ раза.

                        \item Опыт --- работа ЭВМ после ремонта, случайная величина $T$ --- время наработки на отказ.
                        
                        Множество возможных значений $\Xi$ --- теоретически вся правая половина оси абсцисс.
                        
                        Множество возможных значений для этого опыта несчётно.
                    \end{enumerate}

                \paragraph{Классификация случайных величин}

                    В зависимости от вида множества $\Xi$ случайные величины могут быть дискретными и недискретными.
                    
                    \key{Дискретная СВ (ДСВ)} --- если множество её возможных значений счётно или конечно.

                    \key{Недискретная СВ} --- если множество её возможных значений несчётно.

            \subsubsection{Закон распределения случайной величины}

                \key{Закон распределения СВ} --- любое правило (таблица, функция), позволяющее находить вероятности всевозможных событий, связанных со случайной величиной.
                
                То есть закон распределения СВ --- это всякое соотношение, устанавливающее связь между возможными значениями СВ и их вероятностями.
                
                СВ будет полностью описана с вероятностной точки зрения, если мы зададим это распределение, то есть в точности укажем, какой вероятностью обладает каждое событие.
                
                Про случайную величину мы будем говорить, что она подчинена данному закону распределения.

            \subsubsection{Ряд распределения дискретной случайной величины}

                Наиболее простая форма закона распределения дискретной СВ --- ряд распределения.
                
                \key{Ряд распределения} дискретной СВ --- таблица, в которой перечислены в порядке возрастания все возможные значения случайной величины $X$: $x_1 , \: x_2 , \: \ldots , \: x_n , \: \ldots$ и вероятности этих значений $p_1 , \: p_2 , \: \ldots , \: p_n , \: \ldots$, где $p_i = P(X = x_i)$ --- вероятность того, что в результате опыта СВ $X$ примет значение $x_i$ \:$(i = 1 , \: 2 , \: \ldots , \: n , \: \ldots)$.

                Ряд распределения записывается в виде таблицы:

                \begin{tabular}{*{6}{|C{1.8cm}}|}
                    \hline
                    $X$ & $x_1$ & $x_2$ & $\ldots$ & $x_n$ & $\ldots$ \\
                    \hline
                    $P$ & $p_1$ & $p_2$ & $\ldots$ & $p_n$ & $\ldots$ \\
                    \hline
                \end{tabular}

                Так как события $(X = x_1) , \: (X = x_2) , \: \ldots$ несовместны и образуют полную группу, то сумма всех вероятностей, стоящих в нижней строке, равна единице:
                %
                \begin{equation*}
                    \sum\limits_{i} P(X = x_i) = 1 .
                \end{equation*}

                \paragraph{Многоугольник распределения}

                    \key{Многоугольник распределения} --- графическое изображение ряда вероятностей: по оси абсцисс откладываются возможные значения СВ, а по оси ординат --- вероятности этих значений. Для наглядности полученные точки соединяются отрезками прямых.
                    
                    Многоугольник распределения, так же как и ряд распределения, полностью характеризует СВ и является одной из форм закона распределения.

            \subsubsection{Функция распределения случайной величины}

                Наиболее общая форма закона распределения, пригодная для всех случайных величин (как дискретных, так и недискретных) --- функция распределения.
                
                \key{Функция распределения \boldmath$F(X)$} случайной величины $X$ --- вероятность того, что она примет значение меньшее, чем аргумент функции $x$: $F(x) = P(X < x)$.

                Таким образом, функция распределения произвольному числу $x \in \mathbb{R}$ ставит в соответствие вероятность.
                
                Геометрически функция распределения интерпретируется как вероятность того, что случайная точка $X$ попадет левее заданной точки $x$:

                \begin{tikzpicture}
                    \draw [{<[length=12pt, width=6pt]<[length=12pt, width=6pt]}-{>[length=12pt, width=6pt]}]
                        (0, 1) --
                        (6, 1) node [above] {$X < x$};
                    \fill[fill=Light, opacity=0.3]
                        (0, 0)
                        rectangle (6, 0.6);
                    \draw [-{>[length=12pt, width=6pt]}, darkgray, thick]
                        (0, 0) --
                        (8, 0);
                    \draw
                        (6, 0) --
                        (6, 1.2);
                    \fill [fill=Medium]
                        (6, 0)
                        circle (2pt)
                        node [anchor=north west] {$x$};
                \end{tikzpicture}

                Из геометрической интерпретации можно наглядно вывести основные свойства функции распределения.

                \paragraph{Свойства функции распределения}

                    \begin{enumerate}
                        \item $\lim\limits_{n \to -\infty} F(x) = F(-\infty) = 0 .$
                        \item $\lim\limits_{n \to +\infty} F(x) = F(+\infty) = 1 .$
                        \item $F(x)$ --- неубывающая функция своего аргумента, то есть при $x_1 < x_2$ \:$F(x_1) \sleq F(x_2)$.
                        \item $P(\alpha \sleq X < \beta) = F(\beta) - F(\alpha) , \quad \forall \: \alpha , \: \beta \in \mathbb{R}$.
                    \end{enumerate}

                    Доказательство свойства 3 --- на рисунке:

                    \begin{tikzpicture}
                        \draw [{<[length=12pt, width=6pt]<[length=12pt, width=6pt]}-{>[length=12pt, width=6pt]}]
                            (0, 1) --
                            (6, 1) node [above] {$A$};
                        \draw [{<[length=12pt, width=6pt]}-{>[length=12pt, width=6pt]}]
                            (6, 1) --
                            (8, 1) node [above] {$B$};
                        \draw [{<[length=12pt, width=6pt]<[length=12pt, width=6pt]}-{>[length=12pt, width=6pt]}]
                            (0, -1) --
                            (8, -1) node [below] {$C$};
                        \fill[fill=Light, opacity=0.3]
                            (0, 0)
                            rectangle (6, 0.6);
                        \fill[fill=Dark, opacity=0.3]
                            (0, 0)
                            rectangle (8, -0.6);
                        \draw [-{>[length=12pt, width=6pt]}, darkgray, thick]
                            (0, 0) --
                            (10, 0);
                        \draw
                            (6, 0) --
                            (6, 1.2);
                        \draw
                            (8, -1.2) --
                            (8, 1.2);
                        \fill [fill=Medium]
                            (6, 0)
                            circle (2pt)
                            node [anchor=south west] {$x_1$};
                        \fill [fill=Medium]
                            (8, 0)
                            circle (2pt)
                            node [anchor=south west] {$x_2$};
                    \end{tikzpicture}

                    Представим событие $C = (X < x_2)$ как сумму двух несовместных событий $C = A + B$, где $A = (X < x_1)$ и $B = (x_1 \sleq X < x_2)$.

                    По правилу сложения вероятностей
                    %
                    \begin{equation*}
                        P(C) = P(A) + P(B) ,
                    \end{equation*}
                    %
                    то есть
                    %
                    \begin{equation*}
                        P(X < x_2) = P(X < x_1) + P(x_1 \sleq X < x_2) ,
                    \end{equation*}
                    %
                    или
                    %
                    \begin{equation*}
                        F(x_2) = F(x_1) + P(x_1 \sleq X < x_2) .
                    \end{equation*}
                    
                    Но $P(x_1 \sleq X < x_2) \sgeq 0$, следовательно, $F(x_2) \sleq F(x_1)$. \qedd

                    Доказательство свойства 4 вытекает из доказательства свойства 3.

                    Вероятность того, что случайная величина $X$ в результате опыта попадет на участок от $\alpha$ до $\beta$ (включая $\alpha$) равна приращению функции распределения на этом участке.
                    
                    Таким образом, функция распределения $F(x)$ любой СВ --- неубывающая функция своего аргумента, значения которой заключены между 0 и 1: \newline
                    $0 \sleq F(x) \sleq 1$, причём $F(-\infty) = 0 , \: F(+\infty) = 1$.

                \paragraph{Функция распределения дискретной случайной величины}

                    Исходной информацией для построения функции распределения дискретной СВ $X$ является ряд распределения этой СВ:

                    \begin{tabular}{*{5}{|C{1.6cm}}|C{2.8cm}|C{1.8cm}|}
                        \hline
                        $X$ & $x_1$ & $x_2$ & $x_3$ & $\ldots$ & $x_n$ & $> x_n$ \\
                        \hline
                        $P$ & $p_1$ & $p_2$ & $p_3$ & $\ldots$ & $p_n$ & $0$ \\
                        \hline
                        $F(x_1)$ & $0$ & $p_1$ & $p_1 + p_2$ & $\ldots$ &
                            $p_1 + \ldots + p_{n - 1}$ & $1$ \\
                        \hline
                    \end{tabular}
                    %
                    \begin{equation*}
                        \begin{aligned}
                            F(x_i) = ~& P(X < x_i) = \\[1.0ex]
                            & P \big( (X = x_1) \cup (X = x_2) \cup \ldots \cup
                                (X = x_{i - 1}) \big) = \\[1.0ex]
                            & p_1 + p_2 + \ldots + p_{i - 1} .
                        \end{aligned}
                    \end{equation*}

                    $F(x) = \sum\limits_{x_i < x} P(X = x_i)$, то есть суммирование распространяется на все значения $x_i$, которые меньше $x$.

                    Функция распределения любой дискретной СВ --- разрывная ступенчатая функция, скачки которой происходят в точках, соответствующих возможным значениям случайной величины, и равны вероятности этих значений:
                    %
                    \begin{equation*}
                        F(x) = 
                        \begin{cases}
                            0 , \quad & x \sleq x_1 ; \\[1.0ex]
                            p_1 , \quad & x_1 < x \sleq x_2 ; \\[1.0ex]
                            p_1 + p_2 , \quad & x_2 < x \sleq x_3 ; \\[1.0ex]
                            \ldots \\[1.0ex]
                            p_1 + p_2 + \ldots + p_{n - 1} , \quad
                                & x_{n - 1} < x \sleq x_n ; \\[1.0ex]
                            1 , \quad & x > x_n .
                        \end{cases}
                    \end{equation*}

                    Пример: СВ $X$ – количество гербов, выпавших при подбрасывании двух монет.
                    
                    СВ $X$ принимает значения $X = \{ 0, \: 1, \: 2 \}$.
                    
                    Вероятности этих значений: \newline
                    $P(X = 0) = 0,25 ; \:\: P(X = 1) = 0,5 ; \:\: P(X = 2) = 0,25$.
                    
                    Тогда функция распределения этой случайной величины имеет вид:
                    %
                    \begin{equation*}
                        F(x) = 
                        \begin{cases}
                            0 , \quad & x \sleq 0 ; \\[1.0ex]
                            0,25 , \quad & 0 < x \sleq 1 ; \\[1.0ex]
                            0,25 + 0,5 , \quad & 1 < x \sleq 2 ; \\[1.0ex]
                            1 , \quad & x > 2 .
                        \end{cases}
                    \end{equation*}

                    \begin{tikzpicture}
                        \begin{axis}[samples=100, tick label style={font=\footnotesize}, xtick={0, 1, 2}, ytick distance=0.25]
                            \draw [thin, dotted]
                                (0, 0) -- (0, 1);
                            \draw [thin, dotted]
                                (1, 0) -- (1, 1);
                            \draw [thin, dotted]
                                (2, 0) -- (2, 1);
                            \addplot [Medium, thick, densely dotted, domain=-1.001:-0.8]
                                {0};
                            \addplot [Medium, thick, domain=-0.801:0]
                                {0};
                            \addplot [Medium, thick, {<[length=8pt, width=5pt]}-, domain=-0.001:1]
                                {0.25};
                            \addplot [Medium, thick, {<[length=8pt, width=5pt]}-, domain=1.001:2]
                                {0.5};
                            \addplot [Medium, thick, {<[length=8pt, width=5pt]}-, domain=2.001:2.8]
                                {1};
                            \addplot [Medium, thick, densely dotted, domain=2.801:3]
                                {1};
                        \end{axis}
                    \end{tikzpicture}

            \subsubsection{Непрерывная случайная величина}

                \key{Непрерывная СВ (НСВ)} --- если её функция распределения $F(x)$ --- непрерывная, кусочно-дифференцируемая, с непрерывной производной.
                
                Так как для таких случайных величин функция $F(x)$ нигде не имеет скачков, то вероятность любого отдельного значения непрерывной случайной величины равна нулю:
                %
                \begin{equation*}
                    P(X = \alpha) = 0 , \quad \forall \, \alpha .
                \end{equation*}

            \subsubsection{Плотность распределения непрерывной случайной величины}

                Плотность распределения (плотность вероятности) в качестве закона распределения имеет смысл только для непрерывных случайных величин.
                
                Вероятность попадания непрерывной СВ $X$ на участок $\text{от } x \text{ до } x + \Delta x$ равна приращению функции распределения на этом участке:
                %
                \begin{equation*}
                    P(x \sleq X < x + \Delta x) = F(x + \Delta x) - F(x) .
                \end{equation*}
                
                Плотность вероятности на этом участке определяется отношением
                %
                \begin{equation*}
                    \begin{aligned}
                        f(x) = ~& \lim\limits_{\Delta x \to 0}
                            \frac{P(x \sleq X < x + \Delta x)}{\Delta x} = \\[1.0ex]
                        & \lim\limits_{\Delta x \to 0}
                            \frac{F(x + \Delta x) - F(x)}{\Delta x} = \\[1.0ex]
                        & \frac{\dif F(x)}{\dif x} .
                    \end{aligned}
                \end{equation*}

                \key{Плотность распределения (плотностью вероятности) \boldmath$f(x)$} непрерывной СВ $X$ в точке $x$ называется производная её функции распределения $F(x)$ в этой точке.
                
                \key{Кривая распределения} --- график плотности распределения.

                Пусть имеется точка $x$ и прилегающий к ней отрезок $\dif x $.
                
                Вероятность попадания СВ $X$ на этот интервал равна $f(x) \dif x$. Эта величина --- \key{элемент вероятности}.
                
                Вероятность попадания случайной величины X на произвольный участок $[\alpha , \: \beta]$ равна сумме элементарных вероятностей на этом участке:
                %
                \begin{equation*}
                    P(\alpha \sleq x < \beta) = \int\limits_{\alpha}^{\beta} f(x) \dif x .
                \end{equation*}

                В геометрической интерпретации $P(\alpha \sleq x < \beta)$ равна площади, ограниченной сверху кривой плотности распределения $f(x)$ и опирающейся на участок $[\alpha , \: \beta]$:

                \begin{tikzpicture}
                    \begin{axis}[samples=100, tick label style={font=\footnotesize}, xtick={0.5, 1.5}, xticklabels={$\alpha$, $\beta$}, ytick={0}]
                        \addplot+ [name path=A, Medium, thick, domain=-3.001:3, no marks]
                            {e^(-(x^2))};
                        \path [name path=B]
                            (\pgfkeysvalueof{/pgfplots/xmin}, 0) --
                            (\pgfkeysvalueof{/pgfplots/xmax}, 0);
                        \addplot [Light, fill opacity=0.3]
                            fill between [of=A and B, soft clip={domain=0.5:1.5}];
                    \end{axis}
                \end{tikzpicture}

                Это соотношение позволяет выразить функцию распределения $F(x)$ СВ $X$ через её плотность:
                %
                \begin{equation*}
                    F(x) = \int\limits_{-\infty}^{x} f(x) \dif x .
                \end{equation*}

                В геометрической интерпретации $F(x)$ равна площади, ограниченной сверху кривой плотности распределения $f(x)$ и лежащей левее точки $x$:

                \begin{tikzpicture}
                    \begin{axis}[samples=100, tick label style={font=\footnotesize}, xtick={0.5}, xticklabels={$x$}, ytick={0}]
                        \addplot+ [name path=A, Medium, thick, domain=-3.001:3, no marks]
                            {e^(-(x^2))};
                        \path [name path=B]
                            (\pgfkeysvalueof{/pgfplots/xmin}, 0) --
                            (\pgfkeysvalueof{/pgfplots/xmax}, 0);
                        \addplot [Dark, fill opacity=0.3]
                            fill between [of=A and B, soft clip={domain=-3:0.5}];
                    \end{axis}
                \end{tikzpicture}

                \paragraph{Основные свойства плотности распределения}

                    \begin{enumerate}
                        \item Плотность распределения неотрицательна:
                        %
                        \begin{equation*}
                            f(x) \sgeq 0 .
                        \end{equation*}
                        %
                        Это свойство следует из определения $f(x)$ --- производная неубывающей функции не может быть отрицательной.

                        \item \key{Условие нормировки}:
                        %
                        \begin{equation*}
                            \int\limits_{-\infty}^{+\infty} f(x) \dif x = 1 .
                        \end{equation*}
                        %
                        Это свойство следует из формулы выражения функции распределения СВ через её плотность, если положить в ней $x = +\infty$.
                    \end{enumerate}

                    Геометрическая интерпретация основных свойств плотности распределения $f(x)$ СВ:
                    \begin{enumerate}
                        \item Вся кривая распределения лежит не ниже оси абсцисс.
                        \item Площадь, ограниченная кривой распределения и осью абсцисс, равна единице.
                    \end{enumerate}

            \subsubsection{Смешанная случайная величина}
            
                \key{Смешанная СВ (ССВ)} -- если её функция распределения $F(x)$ на некоторых участках непрерывна, а в отдельных точках имеет разрывы (скачки).
                
                На тех участках, где $F(x)$ непрерывна, вероятность каждого отдельного значения СВ равна нулю. Вероятности тех значений, где функция распределения совершает скачки, отличны от нуля и равны величине скачка.

        \newpage
        
        \subsection{Числовые характеристики случайных величин}

            \subsubsection{Определение}

                Законы распределения СВ являются исчерпывающими характеристиками.
                
                Каждый закон распределения представляет собой некоторую функцию, указание которой полностью описывает СВ с вероятностной точки зрения.
                
                Однако часто закон распределения неизвестен и приходится ограничиваться меньшими сведениями.
                
                Зачастую достаточно бывает указать только отдельные числовые параметры, характеризующие отдельные черты распределения, например, среднее значение или разброс СВ (степень случайности).
                
                Эти числа --- \key{числовые характеристики СВ}.

            \subsubsection{Математическое ожидание}

                \key{Математическое ожидание (МО) \boldmath$m_x$} --- среднее взвешенное значение СВ.
                
                Для вычисления математического ожидания дискретной СВ каждое значение $x_i$ учитывается с \key{весом}, пропорциональным вероятности этого значения:
                %
                \begin{equation*}
                    m_x = M[X] = x_1 p_1 + x_2 p_2 + \ldots + x_n p_n =
                        \sum\limits_{i = 1}^{n} x_i p_i .
                \end{equation*}
                %
                Здесь $M[X]$ --- оператор MO, $m_x$ --- полученное число.
                
                Для непрерывной СВ заменим отдельные значения $x_i$ непрерывно изменяющимся параметром $x$, соответствующие вероятности $p_i$ --- элементом вероятности $f(x) \dif x$, а конечную сумму --- интегралом:
                %
                \begin{equation*}
                    M(X) = \int\limits_{-\infty}^{+\infty} x f(x) \dif x .
                \end{equation*}

                Для смешанных случайных величин математическое ожидание состоит из двух слагаемых:
                %
                \begin{equation*}
                    M[X] = \sum\limits_{i = 1} x_i p_i + \int\limits_{H} x \dif F(x) ,
                \end{equation*}
                %
                где сумма распространяется на все значения $x_i$, имеющие отличные от нуля вероятности, а интеграл -- на все участки оси абсцисс, где функция распределения $F(x)$ непрерывна.

                \paragraph{Механическая интерпретация математического ожидания}

                    \key{Механическая интерпретация МО}: \newline
                    на оси абсцисс расположены точки с абсциссами $x_i$, в которых сосредоточены соответственно массы $p_1 , \: p_2 , \: \ldots , \: p_n$, причём $\sum\limits_{i = 1}^{n} p_i = 1$. Тогда МО --- абсцисса центра тяжести.
                    
                    Для непрерывной СВ масса распределена непрерывно с плотностью $f(x)$.

                \paragraph{Физический смысл математического ожидания}

                    \key{Физический смысл MO}: \newline
                    это среднее значение случайной величины, то есть то значение, которое может быть использовано вместо конкретного значения, принимаемого случайной величиной в приблизительных расчетах или оценках.

                \paragraph{Свойства математического ожидания}

                    \begin{enumerate}
                        \item Математическое ожидание неслучайной величины $c$ равно самой величине $c$:
                        %
                        \begin{equation*}
                            M[c] = c .
                        \end{equation*}
                        %
                        \prooff
                        Представим величину $c$ как случайную величину, которая принимает одно и то же значение $c$ с вероятностью $p = 1$:
                        %
                        \begin{equation*}
                            M[c] = c \cdot 1 = c . \qedd
                        \end{equation*}
                        
                        \item При умножении СВ $X$ на неслучайную величину $c$ на ту же самую величину увеличится её математическое ожидание:
                        %
                        \begin{equation*}
                            M(c \cdot X) = c \cdot M(X) .
                        \end{equation*}
                        %
                        \prooff
                        %
                        \begin{equation*}
                            M(c \cdot X) =
                                c \cdot x_1 \cdot p_1 + \ldots + c \cdot x_n \cdot p_n =
                                c \, (x_1 \cdot p_1 + \ldots + x_n \cdot p_n) . \qedd
                        \end{equation*}
                        
                        \item При прибавлении к СВ $X$ неслучайной величины $c$ к её математическому ожиданию прибавляется такая же величина:
                        %
                        \begin{equation*}
                            M(c + X) = c + M(X) .
                        \end{equation*}
                        %
                        \prooff
                        %
                        \begin{equation*}
                            \begin{aligned}
                                M(c + X) = ~& (c + x_1) \cdot p_1 +
                                    \ldots + (c + x_n) \cdot p_n = \\[1.0ex]
                                & c (p_1 + \ldots + p_n) +
                                    (x_1 \cdot p_1 + \ldots + x_n \cdot p_n) = \\[1.0ex]
                                & c \cdot 1 + M(X) = c + M(X) .
                            \end{aligned} \qedd*{-4.3ex}
                        \end{equation*}
                        
                        \item Математическое ожидание суммы двух случайных величин равно сумме их математических ожиданий:
                        %
                        \begin{equation*}
                            M(X + Y) = M(X) + M(Y) .
                        \end{equation*}
                    \end{enumerate}

            \subsubsection{Моменты случайной величины}

                Понятие момента широко применяется в механике для описания распределения масс (статические моменты, моменты инерции и так далее). Теми же приемами пользуются и в теории вероятностей.
                
                На практике чаще всего применяются моменты двух видов: начальные и центральные.
                
                \key{Начальный момент \boldmath$s$-го порядка \boldmath$\nu_s$} СВ $X$ --- это МО $s$-й степени этой СВ:
                %
                \begin{equation*}
                    \nu_s = M(X^s) .
                \end{equation*}
                %
                \begin{equation*}
                    \nu_k (x) = M(X^s) = 
                        \begin{cases}
                            \sum\limits_{i = 1}^{n} x_i^s P(X = x_i) \quad
                                & \text{для ДСВ} ; \\[2.0ex]
                            \int\limits_{-\infty}^{+\infty} x^s f(x) \dif x \quad
                                & \text{для НСВ} ; \\[2.0ex]
                            \sum\limits_{i} x_i^s P(X = x_i) +
                                \int\limits_{H} x^s f(x) \dif x \quad
                                & \text{для ССВ} .
                        \end{cases}
                \end{equation*}

                МО СВ является начальным моментом первого порядка.

                \key{Центрированная СВ \boldmath$\overset{\hspace{3pt}\circ}{X}$} --- отклонение СВ от её МО:
                %
                \begin{equation*}
                    \overset{\hspace{3pt}\circ}{X} = X - m_x .
                \end{equation*}

                Центрирование СВ аналогично переносу начала координат в среднюю, центральную точку, абсцисса которой равна МО СВ.
                
                \key{Центральный момент $s$-го порядка \boldmath$\mu_s$} СВ $X$ --- это МО $s$-й степени центрированной СВ:
                %
                \begin{equation*}
                    \mu_k (x) = M(\overset{\hspace{3pt}\circ}{X} \vphantom{X}^s)
                \end{equation*}
                %
                \begin{equation*}
                    \mu_k (x) = M(\overset{\hspace{3pt}\circ}{X} \vphantom{X}^s) = 
                        \begin{cases}
                            \sum\limits_{i = 1}^{n} (x_i - m_x)^s P(X = x_i) \quad
                                & \text{для ДСВ} ; \\[2.0ex]
                            \int\limits_{-\infty}^{+\infty} (x - m_x)^s f(x) \dif x \quad
                                & \text{для НСВ} ; \\[2.0ex]
                            \sum\limits_{i} (x_i - m_x)^s P(X = x_i) +
                                \int\limits_{H} (x - m_x)^s f(x) \dif x \quad
                                & \text{для ССВ} .
                        \end{cases}
                \end{equation*}

                Очевидно, что для любой случайной величины $X$ центральный момент первого порядка равен нулю:
                %
                \begin{equation*}
                    \mu_1 (x) = M(\overset{\hspace{3pt}\circ}{X}) =
                        M(X - m_x) = M(X) - m_x = 0 .
                \end{equation*}

                Некоторые соотношения, связывающие начальные и центральные моменты:

                Для второго центрального момента:
                %
                \begin{equation*}
                    \begin{aligned}
                        \mu_2 (x) = ~& M(\overset{\hspace{3pt}\circ}{X} \vphantom{X}^2) = \\[1.0ex]
                        & \sum\limits_{i = 1}^{n} (x_i - m_x)^2 p_i = \\[1.0ex]
                        & \sum\limits_{i = 1}^{n} x_i^2 p_i -
                            2 m_x \sum\limits_{i = 1}^{n} x_i p_i +
                            m_x^2 \sum\limits_{i = 1}^{n} p_i = \\[1.0ex]
                        & \nu_2 - m_x^2 .
                    \end{aligned}
                \end{equation*}

                Для третьего центрального момента:
                %
                \begin{equation*}
                    \begin{aligned}
                        \mu_3 (x) = ~& M(\overset{\hspace{3pt}\circ}{X} \vphantom{X}^3) = \\[1.0ex]
                        & \sum\limits_{i = 1}^{n} (x_i - m_x)^3 p_i = \\[1.0ex]
                        & \sum\limits_{i = 1}^{n} x_i^3 p_i -
                            3 m_x \sum\limits_{i = 1}^{n} x_i^2 p_i +
                            3 m_x^2 \sum\limits_{i = 1}^{n} x_i p_i +
                            m_x^3 \sum\limits_{i = 1}^{n} p_i = \\[1.0ex]
                        & \nu_3 - 3 \nu_2 m_x + 2 m_x^3 .
                    \end{aligned}
                \end{equation*}

                Аналогично можно получить моменты не только относительно начала координат (начальные моменты) или математического ожидания (центральные моменты), но и относительно произвольной точки $a$.

            \subsubsection{Дисперсия}

                \key{Дисперсия \boldmath$D$} случайной величины $X$ --- математическое ожидание квадрата соответствующей центрированной случайной величины.
                
                Дисперсия характеризует степень разброса значений случайной величины относительно её математического ожидания, то есть ширину диапазона значений.
                
                Расчётные формулы:
                %
                \begin{equation*}
                    D[X] = M[\overset{\hspace{3pt}\circ}{X} \vphantom{X}^2] = 
                        \begin{cases}
                            \sum\limits_{i = 1}^{n} (x_i - m_x)^2 P(X = x_i) \quad
                                & \text{для ДСВ} ; \\[2.0ex]
                            \int\limits_{-\infty}^{+\infty} (x - m_x)^2 f(x) \dif x \quad
                                & \text{для НСВ} ; \\[2.0ex]
                            \sum\limits_{i} (x_i - m_x)^2 P(X = x_i) +
                                \int\limits_{H} (x - m_x)^2 f(x) \dif x \quad
                                & \text{для ССВ} .
                        \end{cases}
                \end{equation*}

                Дисперсия может быть вычислена через второй начальный момент:
                %
                \begin{equation*}
                    \begin{aligned}
                        D[X] = ~& M[(x - m_x)^2] = M[x^2 - 2 x m_x + m_x^2] = \\[1.0ex]
                        & M[x^2] - 2 m_x \cdot M[X] + m_x^2 = M[x^2] - m_x^2 .
                    \end{aligned}
                \end{equation*}

                Дисперсия случайной величины характеризует степень рассеивания (разброса) значений случайной величины относительно её математического ожидания.
                
                Дисперсия случайной величины (как дискретной, так и непрерывной) --- неслучайная (постоянная) величина.
                
                Дисперсия СВ имеет размерность квадрата случайной величины.
                
                Для наглядности характеристики рассеивания пользуются величиной, размерность которой совпадает с размерностью случайной величины:

                \key{Среднее квадратическое отклонение (СКО) \boldmath$\sigma$} случайной величины $X$ --- это характеристика
                %
                \begin{equation*}
                    \sigma_x = \sigma [X] = \sqrtt{D[X]} .
                \end{equation*}

                Среднее квадратическое отклонение измеряется в тех же физических единицах, что и случайная величина, и характеризует ширину диапазона значений случайной величины.

                \paragraph{Свойства дисперсии}

                    \begin{enumerate}
                        \item Дисперсия постоянной величины $c$ равна нулю:
                        %
                        \begin{equation*}
                            D[c] = 0 .
                        \end{equation*}
                        %
                        \prooff
                        По определению дисперсии,
                        %
                        \begin{equation*}
                            D[c] = M[(c - M[c])^2] = M[(c - c)^2] = M[0] = 0 . \qedd
                        \end{equation*}
                        
                        \item При прибавлении к случайной величине $X$ неслучайной величины $c$ её дисперсия не меняется.
                        %
                        \begin{equation*}
                            D[X + c] = D[X] .
                        \end{equation*}
                        %
                        \prooff
                        По определению дисперсии,
                        %
                        \begin{equation*}
                            \begin{aligned}
                                D[X + c] = ~& M \big[ \big( (X + c) +
                                    (m_x - c)^2 \big) \big] = \\[1.0ex]
                                & M \big[ (X + c - m_x - c)^2 \big] =
                                    M \big[ (X - m_x)^2 \big] = D[X] .
                            \end{aligned} \qedd*{-2.2ex}
                        \end{equation*}

                        \item При умножении случайной величины $X$ на неслучайную величину $c$ её дисперсия умножается на $c^2$:
                        %
                        \begin{equation*}
                            D[c X] = c^2 D[X] .
                        \end{equation*}
                        %
                        \prooff
                        По определению дисперсии,
                        %
                        \begin{equation*}
                            \begin{aligned}
                                D[c X] = ~& M \big[ \big( c X + M[c X]^2 \big) \big] =
                                    M \big[ (c x - c m_x)^2 \big] \\[1.0ex]
                                & M \big[ c^2 (x - m_x)^2 \big] =
                                    c^2 M \big[ (X - m_x)^2 \big] = c^2 D[X] .
                            \end{aligned} \qedd*{-2.2ex}
                        \end{equation*}

                        Для среднего квадратичного отклонения это свойство имеет вид
                        %
                        \begin{equation*}
                            \sigma [c X] = |c| \cdot \sigma [X] .
                        \end{equation*}
                    \end{enumerate}

                    При $|c| > 1$ величина $c X$ имеет возможные значения (по абсолютной величине), большие, чем величина $X$. Следовательно, эти значения рассеяны вокруг математического ожидания $M[c X]$ больше, чем возможные значения $X$ вокруг $M[X]$, то есть $D[c X] > D[X]$.
                    
                    Если $0 < c < 1$, то $D[c X] < D[X]$.

                    \key{Правило трёх сигм}: \newline
                    Для большинства значений случайной величины абсолютная величина её отклонения от математического ожидания не превосходит утроенного среднего квадратического отклонения, или, другими словами, практически все значения случайной величины находятся в интервале
                    %
                    \begin{equation*}
                        [m - 3 \sigma ; \: m + 3 \sigma] .
                    \end{equation*}

            \subsubsection{Дополнительные характеристики случайной величины}

                \paragraph{Мода}
            
                    \key{Мода \boldmath$M_o$} случайной величины --- её наиболее вероятное значение, то есть то значение, для которого вероятность $p_i$ (для дискретной случайной величины) или $f(x)$ (для непрерывной случайной величины) достигает максимума.

                    \key{Унимодальное} распределение --- с одним максимумом ряда распределения (для дискретной случайной величины) или плотности вероятности (для непрерывной случайной величины).
                        
                    \key{Полимодальное} распределение --- если многоугольник распределения или кривая распределения имеют несколько локальных максимумов.
                        
                    \key{Антимодальное} распределение --- если оно обладает не максимумом, а минимумом.

                \paragraph{Медиана}

                    \key{Медиана \boldmath$M_e$} случайной величины $X$ --- такое её значение, для которого выполняется условие $P(X < M_e) = P(X > M_e)$.
                    
                    Медиана, как правило, существует только для непрерывных случайных величин:
                    %
                    \begin{equation*}
                        \begin{aligned}
                            \int\limits_{-\infty}^{M_e} f(x) \dif x & = 0,5 ; \\[1.0ex]
                            \int\limits_{M_e}^{+\infty} f(x) \dif x & = 0,5 .
                        \end{aligned}
                    \end{equation*}

                    Если известна функция распределения случайной величины $X$, то $M_e$ --- решение уравнения
                    %
                    \begin{equation*}
                        F(M_e) = F(x) = 0,5 .
                    \end{equation*}

                Для решения обратной задачи используются следующие понятия:

                \paragraph{Квантиль}

                    \key{Квантиль \boldmath$\chi_p$} --- значение, которое заданная случайная величина не превышает с фиксированной вероятностью $p$:
                    %
                    \begin{equation*}
                        P(X < \chi_p) = F(\chi_p) = p .
                    \end{equation*}
                    
                    Так как для непрерывной случайной величины $X$ функция $F(X)$ непрерывна, существуют квантили для $\forall \, p, \: 0 < p < 1$.

                    0,5-квантиль распределения --- медиана:
                    %
                    \begin{equation*}
                        \chi_{0,5} = M_e .
                    \end{equation*}

                    $k$-ой $q$-квантилью называется квантиль уровня $\frac{k}{q}$, то есть $\big( \frac{k}{q} \big)$-квантиль.

                    Некоторые $q$-квантили имеют специальные названия:

                    \subparagraph{Квартиль}

                        \key{\boldmath$q$-й квартиль} --- квантиль уровня $\frac{q}{4}$.

                        \key{Первый}, или \key{нижний}, \key{квартиль} распределения --- 0,25-квантиль:
                        %
                        \begin{equation*}
                            Q_1 = \chi_{0,25} .
                        \end{equation*}
                        
                        \key{Второй квартиль} распределения, или медиана --- 0,5-квантиль:
                        %
                        \begin{equation*}
                            Q_2 = \chi_{0,5} = M_e .
                        \end{equation*}
                        
                        \key{Третий}, или \key{верхний}, \key{квартиль} распределения --- 0,75-квантиль:
                        %
                        \begin{equation*}
                            Q_3 = \chi_{0,75} .
                        \end{equation*}

                    \subparagraph{Дециль}

                        \key{\boldmath$d$-й дециль} --- квантиль уровня $\frac{d}{10}$.

                        5-й дециль распределения --- 0,5-квантиль --- медиана:
                        %
                        \begin{equation*}
                            D_5 = \chi_{0,5} = M_e .
                        \end{equation*}
                
                    \subparagraph{Персентиль}

                        \key{\boldmath$p$-й персентиль} --- квантиль уровня $\frac{p}{100}$.

                        50-й персентиль распределения --- 0,5-квантиль --- медиана:
                        %
                        \begin{equation*}
                            P_{50} = \chi_{0,5} = M_e .
                        \end{equation*}

                \paragraph{Третий центральный момент}

                    Третий центральный момент служит для характеристики \key{асимметрии} распределения.
                    
                    Если распределение \key{симметрично} относительно математического ожидания (масса распределена равномерно относительно центра тяжести), то все моменты нечётного порядка равны нулю.
                    
                    Поэтому для характеристик асимметрии выбирают третий центральный момент --- он имеет размерность куба случайной величины.
                    
                    Безразмерный коэффициент асимметрии вычисляется так:
                    %
                    \begin{equation*}
                        S_k = \frac{\mu_3}{\sigma^3} .
                    \end{equation*}

                \paragraph{Четвёртый центральный момент}

                    Четвертый центральный момент служит для характеристики так называемой \key{крутости}, то есть островершинности или плосковершинности распределения.
                    
                    Это свойство распределения описывается с помощью \key{эксцесса}:
                    %
                    \begin{equation*}
                        E_x = \frac{\mu_4}{\sigma^4} - 3 .
                    \end{equation*}

                \paragraph{Коэффициент вариации}

                    Коэффициент вариации безразмерная величина, характеризует степень разбросанности значений случайной величины и вычисляется по формуле
                    %
                    \begin{equation*}
                        \upsilon_x = \frac{\delta_x}{m_x} .
                    \end{equation*}

            \subsubsection{Производящие функции}

                В ряде случаев для определения важнейших числовых характеристик дискретных случайных величин может помочь аппарат производящих функций.
                
                Пусть имеется дискретная случайная величина $X$, принимающая неотрицательные целочисленные значения $0 , \: 1 , \: \ldots , \: k , \: \ldots$ с вероятностями $p_0 , \: p_1 , \: \ldots , \: p_k , \: \ldots ; \:\: p_k = P(X = k)$.
                
                \key{Производящая функция} случайной величины $X$ --- это функция вида
                %
                \begin{equation*}
                    \varphi (z) = \sum\limits_{i = 0}^{\infty} p_k z^k ,
                \end{equation*}
                %
                где $z$ --- произвольный параметр ($0 < z \sleq 1$).

                Очевидно, что
                %
                \begin{equation*}
                    \varphi (1) = \sum\limits_{i = 0}^{\infty} p_k = 1 .
                \end{equation*}

                Возьмём первую производную по $z$ от производящей функции:
                %
                \begin{equation*}
                    \varphi ' (z) = \sum\limits_{i = 0}^{\infty} k p_k z^{k - 1}
                \end{equation*}
                %
                и положим в ней $z = 1$:
                %
                \begin{equation*}
                    \varphi ' (z = 1) = \sum\limits_{k = 1}^{\infty} k p_k
                \end{equation*}
                %
                --- получили математическое ожидание случайной величины $X$.

                Таким образом, математическое ожидание неотрицательной целочисленной случайной величины равно первой производной её производящей функции $\varphi (z)$ при $z = 1$.

                Возьмём вторую производную функции $\varphi (z)$:
                %
                \begin{equation*}
                    \varphi '' (z) = \sum\limits_{i = 0}^{\infty} k (k - 1) p_k z^{k - 2}
                \end{equation*}
                %
                и положим в ней $z = 1$:
                %
                \begin{equation*}
                    \varphi '' (z = 1) = \sum\limits_{k = 1}^{\infty} (k^2 - k) p_k =
                        \sum\limits_{k = 1}^{\infty} k^2 p_k -
                        \sum\limits_{k = 1}^{\infty} k p_k
                \end{equation*}
                %
                --- первая сумма --- второй начальный момент $\nu_2$ случайной величины $X$, вторая сумма --- её математическое ожидание.

                Тогда
                %
                \begin{equation*}
                    \nu_2 [X] = \varphi '' (z = 1) + \varphi ' (z = 1) ,
                \end{equation*}
                %
                то есть второй начальный момент случайной величины равен сумме второй производной от производящей функции при $z = 1$ и её математического ожидания.

                Аналогично, берем третью производную
                %
                \begin{equation*}
                    \varphi ''' (z) =
                        \sum\limits_{k = 1}^{\infty} k (k - 1) (k - 2) p^{k - 3}
                \end{equation*}
                %
                и, полагая в ней $z = 1$, получаем
                %
                \begin{equation*}
                    \varphi ''' (z = 1) = \nu_3 - 3 \nu_2 + 2 m .
                \end{equation*}
                
                И так далее, что позволяет выразить начальные моменты более высокого порядка.

        \newpage

        \subsection{Типовые распределения случайных величин}

            \subsubsection{Типовые законы распределения дискретных случайных величин}

                \paragraph{Геометрическое распределение}

                    Дискретная случайная величина $X$ имеет \key{геометрическое распределение}, если вероятности её возможных значений $0 , \: 1 , \: \ldots , \: k , \: \ldots$ определяются так:
                    %
                    \begin{equation*}
                        p_k = P(X = k) = q^k p ,
                    \end{equation*}
                    %
                    где $p$ --- параметр распределения, ($0 \sleq p \sleq 1$), а $q = 1 - p$.

                    \begin{tabular}{*{7}{|C{1.8cm}}|}
                        \hline
                        $x_i$ & 0 & 1 & 2 & $\ldots$ & $k$ & $\ldots$ \\
                        \hline
                        $p_i$ & $p$ & $q p$ & $q^2 p$ & $\ldots$ & $q^k p$ & $\ldots$ \\
                        \hline
                    \end{tabular}

                    На практике геометрическое распределение появляется при следующих условиях:
                    
                    Пусть производится некоторый опыт, в котором некоторое событие появляется с вероятностью $p$. Опыты производятся последовательно, до наступления события.
                    
                    Случайная величина $X$, равная числу неудачных опытов, имеет геометрическое распределение.
                    
                    Числовые характеристики геометрического распределения:
                    %
                    \begin{equation*}
                        \begin{aligned}
                            M[X] & = \frac{q}{p} , \\[1.0ex]
                            D[X] & = \frac{q}{p^2} .
                        \end{aligned}
                    \end{equation*}

                    \subparagraph{Смещённое геометрическое распределение}

                        Смещённое геометрическое распределение получается из геометрического путём преобразования случайной величины $X$ в случайную величину $Y = X + 1$.
                        
                        Дискретная случайная величина $Y$ имеет \key{смещённое геометрическое распределение}, если вероятности её возможных значений $0 , \: 1 , \: \ldots , \: k , \: \ldots$ определяются так:
                        %
                        \begin{equation*}
                            p_k = P(Y = k) = q^{k - 1} p ,
                        \end{equation*}
                        %
                        где $p$ --- параметр распределения, ($0 \sleq p \sleq 1$), а $q = 1 - p$.

                        \begin{tabular}{*{7}{|C{1.8cm}}|}
                            \hline
                            $x_i$ & 1 & 2 & 3 & $\ldots$ & $k$ & $\ldots$ \\
                            \hline
                            $p_i$ & $p$ & $q p$ & $q^2 p$ & $\ldots$ & $q^{k - 1} p$ & $\ldots$ \\
                            \hline
                        \end{tabular}

                        Числовые характеристики смещённого геометрического распределения определяются с использованием их свойств:
                        %
                        \begin{equation*}
                            \begin{aligned}
                                M[Y] & = M[X + 1] = M[X] + 1 =
                                    \frac{q}{p} + 1 = \frac{1}{p} , \\[1.0ex]
                                D[Y] & = D[X + 1] = D[X] = \frac{q}{p^2} .
                            \end{aligned}
                        \end{equation*}

            \subsubsection{Индикатор случайного события}

                Индикатор случайного события $A$ --- величина $X$, если она равна 1 при осуществлении события $A$ и 0 при осуществлении $\nix{A}$:
                %
                \begin{equation*}
                    X =
                        \begin{cases}
                            1 , \quad & A ; \\[1.0ex]
                            0 , \quad & \nix{A} .
                        \end{cases}
                \end{equation*}
                %               
                Ряд распределения вероятностей:

                \begin{tabular}{*{3}{|C{2.6cm}}|}
                    \hline
                    $x_i$ & 0 & 1  \\
                    \hline
                    $P_i$ & $q$ & $p$  \\
                    \hline
                \end{tabular}

                где $P_i$ --- вероятность наступления события $A$.

                Числовые характеристики индикатора события:
                %
                \begin{equation*}
                    \begin{aligned}
                        M[X] & = 0 \cdot q + 1 \cdot p = p , \\[1.0ex]
                        M[X^2] & = 0^2 \cdot q + 1^2 \cdot p = p , \\[1.0ex]
                        D[X] & = M[X^2] - m_x^2 = p - p^2 = p (1 - p) = p q , \\[1.0ex]
                        \sigma_x & = \sqrtt{p q} .
                    \end{aligned}
                \end{equation*}

            \subsubsection{Биноминальный закон распределения}

                Дискретная случайная величина $X$ имеет \key{биноминальное распределение}, если её закон распределения описывается \key{формулой Бернулли}:
                %
                \begin{equation*}
                    P(X = k) = P(n, \: k) = C_n^k p^k q^{n - k} ,
                \end{equation*}
                %
                где $p$ --- параметр распределения, ($0 \sleq p \sleq 1$), а $q = 1 - p$.

                Распределение зависит от двух параметров: $n$ и $p$.

                На практике биноминальное распределение возникает при следующих условиях:
                
                Пусть производится серия из $n$ испытании, в каждом из которых некоторое событие появляется с вероятностью $p$.
                
                Случайная величина $X$, равная числу наступлений события в $n$ опытах, имеет биноминальное распределение.
                
                Числовые характеристики:
                %
                \begin{equation*}
                    \begin{aligned}
                        M[X] & = n , \\[1.0ex]
                        D[X] & = n p q .
                    \end{aligned}
                \end{equation*}
                
                Название объясняется тем, что правую часть равенства можно рассматривать как общий член разложения \key{бинома Ньютона}:
                %
                \begin{equation*}
                    \begin{aligned}
                        & (p + q)^n = C_n^0 p^0 q^n + C_n^n p^1 q^{n - 1} + \ldots +
                            C_k^n p^k q^{n - k} + C_n^n p^n q^0 = 1 , \\[1.0ex]
                        & p + q = 1 ,
                    \end{aligned}
                \end{equation*}
                %
                то есть
                %
                \begin{equation*}
                    \sum\limits_{k = 0}^{n} P_n (k) =
                        \sum\limits_{k = 0}^{n} C_n^k p^k q^{n - k} = 1 .
                \end{equation*}

            \subsubsection{Распределение Пуассона}

                Соотношениями, описывающими биноминальное распределение, удобно пользоваться в тех случаях, когда число $n$ велико, а величина $p$ достаточно мала.

                \theorr
                Если $n \to \infty$, а $p \to 0$ так, что $n p = \lambda \:\: (0 < \lambda < 1)$, то
                %
                \begin{equation*}
                    P(X = k) = C_n^k p^k q^{n - k} = \frac{\lambda^k}{k!} e^{-\lambda}
                \end{equation*}
                %
                при любом $k = 0, \: 1, \: \ldots$.

                Числовые характеристики:
                %
                \begin{equation*}
                    \begin{aligned}
                        M[X] & = \lambda , \\[1.0ex]
                        D[X] & = \lambda .
                    \end{aligned}
                \end{equation*}

                Закон Пуассона зависит от одного параметра $\lambda$, смысл которого заключается в следующем: он является одновременно и математическим ожиданием, и дисперсией случайной величины $X$.

                \paragraph{Физические условия возникновения распределения Пуассона}

                    Рассмотрим временную ось, на которой будем отмечать моменты возникновения случайных событий (например, отказы компонентов в сложном техническом устройстве, заявки на обслуживание).
                    
                    \key{Стационарный} поток случайных событий --- если число событий, приходящихся на участок $\tau$ в общем случае не зависит от расположения этого участка на временной оси и определяется только его длительностью, то есть среднее число событий в единице времени $\Delta t$ --- \key{интенсивность потока \boldmath$\lambda$} --- постоянно.
                    
                    \key{Ординарный} поток случайных событий --- если вероятность попадания в некоторый участок $\tau$ двух и более случайных событий пренебрежимо мала по сравнению с вероятностью попадания на него одного события.
                    
                    \key{Отсутствует последействие} в потоке --- если вероятность попадания событий на участок $\tau$ не зависит от того, сколько событий попало на другие участки, не пересекающиеся с данным.
                    
                    \key{Простейший}, или \key{Пуассоновский}, поток случайных событий --- если он является стационарным, ординарным и без последействия.
                    
                    Для пуассоновского потока число событий, поступивших в течение интервала $\tau$, является дискретной случайной величиной с распределением Пуассона с параметром $\alpha = \lambda \tau$.

            \subsubsection{Типовые законы распределения непрервных случайных величин}

                \paragraph{Равномерное распределение}

                    Непрерывная случайная величина $X$ \key{равномерно распределена} в интервале $[a ; \: b]$, если её плотность вероятности в этом интервале постоянна, то есть если все значения в этом интервале равновероятны:
                    %
                    \begin{equation*}
                        f(x) =
                            \begin{cases}
                                c , \quad & a \sleq x \sleq b ; \\[1.0ex]
                                0 , \quad & x \sleq a , \:\: x \sgeq b .
                            \end{cases}
                    \end{equation*}

                    Значение постоянной $c$ определяется из условия нормировки:
                    %
                    \begin{equation*}
                        \begin{aligned}
                            1 & = \int\limits_{-\infty}^{+\infty} f(x) \dif x =
                                0 + \int\limits_{a}^{b} c \dif x + 0 =
                                c (b - a) \Rightarrow \\[1.0ex]
                            c & = \frac{1}{b - a} .
                        \end{aligned}
                    \end{equation*}

                    Функция распределения:
                    %
                    \begin{equation*}
                        F(x) =
                        \begin{cases}
                            0 , \quad & x < a ; \\[2.0ex]
                            \dfrac{x - a}{b - a} , \quad & a \sleq x \sleq b ; \\[2.0ex]
                            1 , \quad & x > b .
                        \end{cases}
                    \end{equation*}

                    Числовые характеристики равномерно распределённой случайной величины:
                    %
                    \begin{equation*}
                        \begin{aligned}
                            M[X] = ~& \int\limits_{-\infty}^{+\infty} x f(x) \dif x = \\[1.0ex]
                            & \int\limits_{-\infty}^{a} x f(x) \dif x +
                                \int\limits_{a}^{b} x f(x) \dif x +
                                \int\limits_{b}^{+\infty} x f(x) \dif x = \\[1.0ex]
                            & \int\limits_{a}^{b} \frac{x}{b - a} \dif x = \\[1.0ex]
                            & \frac{1}{b - a} \cdot \frac{x^2}{2} \bigg|_{a}^{b} =
                                \frac{b^2 - a^2}{2 (b - a)} = \frac{b - a}{2} .
                        \end{aligned}
                    \end{equation*}
                    %
                    \begin{equation*}
                        \begin{aligned}
                            D[X] = ~& \int\limits_{-\infty}^{+\infty}
                                (x - a)^2 f(x) \dif x = \\[1.0ex]
                            & \int\limits_{-\infty}^{a} (x - a)^2 f(x) \dif x +
                                \int\limits_{a}^{b} (x - a)^2 f(x) \dif x +
                                \int\limits_{b}^{+\infty} (x - a)^2 f(x) \dif x = \\[1.0ex]
                            & \int\limits_{a}^{b} \frac{(x - a)^2}{b - a} \dif x = \\[1.0ex]
                            & \frac{1}{b - a} \cdot \frac{(x - a)^3}{3} \bigg|_{a}^{b} =
                                \frac{(x - \frac{a + b}{2})^3}{3 (b - a)}
                                \bigg|_{a}^{b} = \\[3.0ex]
                            & \frac{(b - \frac{a + b}{2})^3 -
                                (a - \frac{a + b}{2})^3}{3 (b - a)} =
                                \frac{(b - a)^2}{12} .
                        \end{aligned}
                    \end{equation*}

                    Среднее квадратичное отклонение равномерного распределения:
                    %
                    \begin{equation*}
                        \sigma_x = \frac{b - a}{2 \sqrtt{3}} .
                    \end{equation*}

                    Равномерное распределение случайной величины полностью определяется двумя параметрами: $a$ и $b$ --- интервалом, на котором определена случайная величина.

                    При необходимости можно определить параметры $a$ и $b$ равномерного распределения по известным значениям математического ожидания $m_x$ и дисперсии $D[X]$ случайной величины.
                    
                    Для этого составляется система уравнений следующего вида:
                    %
                    \begin{equation*}
                        \begin{cases}
                            \dfrac{a + b}{2} = m_x; \\[2.0ex]
                            \dfrac{b - a}{2 \sqrtt{3}} = \sigma_x ,
                        \end{cases}
                    \end{equation*}
                    %
                    из которой определяются искомые параметры.

                    Вероятность попадания равномерно распределённой случайной величины в интервал $[\alpha ; \: \beta]$ определяется так:
                    %
                    \begin{equation*}
                        P(\alpha \sleq X \sleq \beta) =
                            \int\limits_{\alpha}^{\beta} f(x) \dif x =
                            \int\limits_{\alpha}^{\beta} \frac{1}{b - a} \dif x =
                            \frac{1}{b - a} \int\limits_{\alpha}^{\beta} \dif x =
                            \frac{\beta - \alpha}{b - a} ,
                    \end{equation*}
                    %
                    где $[\alpha ; \: \beta] \in [a ; \: b]$.

                    Например, шкала измерительного прибора проградуирована в некоторых единицах.
                    
                    Случайная величина $X$ --- ошибка при округлении до ближайшего целого деления, которая с постоянной плотностью вероятности принимает любое значение между двумя соседними делениями:
                    %
                    \begin{equation*}
                        X \in [k ; \: k + 1] .
                    \end{equation*}
                    
                    Ошибка измерения имеет равномерное распределение на интервале $\big( \frac{1}{2} ; \: \frac{1}{2} \big)$.

                \paragraph{Показательное, или экспоненциальное, распределение}

                    Непрерывная случайная величина $X$, принимающая только положительные значения, имеет \key{показательное}, или \key{экспоненциальное}, \key{распределение}, если
                    %
                    \begin{equation*}
                        f(x) =
                        \begin{cases}
                            0 , \quad & x \sleq 0 ; \\[1.0ex]
                            \lambda e^{-\lambda x} , \quad & x > 0 .
                        \end{cases}
                    \end{equation*}

                    \key{Параметр \boldmath$\lambda$} показательного распределения --- положительная величина, полностью его определяющая.

                    Определим функцию распределения случайной величины:

                    \begin{enumerate}
                        \item При $t < 0$:
                        %
                        \begin{equation*}
                            F(t) = \int\limits_{-\infty}^{t} f(t) \dif t =
                                \int\limits_{-\infty}^{t} 0 \dif t = 0 .
                        \end{equation*}

                        \item При $t \sgeq 0$:
                        %
                        \begin{equation*}
                            \begin{aligned}
                                F(t) = ~& \int\limits_{-\infty}^{t} f(t) \dif t =
                                    \int\limits_{-\infty}^{0} 0 \dif t +
                                    \int\limits_{0}^{t} \lambda e^{-\lambda t} \dif t = \\[1.0ex]
                                & -e^{-\lambda t} \big|_{0}^{t} =
                                    -(e^{-\lambda t} - e^0) = 1 - e^{-\lambda t} .
                            \end{aligned}
                        \end{equation*}
                    \end{enumerate}

                    Таким образом, функция распределения имеет вид
                    %
                    \begin{equation*}
                        F(x) =
                        \begin{cases}
                            0 , \quad & x < 0 ; \\[1.0ex]
                            1 - \lambda e^{-\lambda x} , \quad & x \sgeq 0 .
                        \end{cases}
                    \end{equation*}

                    График плотности распределения вероятностей экспоненциального распределения:

                    \begin{tikzpicture}
                        \begin{axis}[samples=100, tick label style={font=\footnotesize}, xtick={0}, ytick={0, 2}, yticklabels={0, $\lambda$}]
                            \addplot [Light, thick, domain=0:3]
                                {2 * e^(-2 * x)};
                        \end{axis}
                    \end{tikzpicture}

                    График функции распределения вероятностей экспоненциального распределения:

                    \begin{tikzpicture}
                        \begin{axis}[samples=100, tick label style={font=\footnotesize}, xtick={0}, ytick={0, 1}]
                            \draw [thin, dotted]
                                (0, 1) -- (3, 1);
                            \addplot [Dark, thick, domain=0:3]
                                {1 - e^(-2 * x)};
                        \end{axis}
                    \end{tikzpicture}

                    Числовые характеристики случайной величины:
                    %
                    \begin{equation*}
                        M[X] = \int\limits_{0}^{\infty} x f(x) \dif x =
                            \lambda \int\limits_{0}^{\infty} x e^{-\lambda x} \dif x .
                    \end{equation*}

                    Проводя интегрирование по частям и учитывая, что при $x \to \infty \:\: e^x$ стремится к нулю быстрее, чем возрастает любая степень $x$, находим
                    %
                    \begin{equation*}
                        m_x = \frac{1}{\lambda} .
                    \end{equation*}

                    Дисперсию случайной величины определяем по формуле
                    %
                    \begin{equation*}
                        D[X] = \nu_2 - m_x^2 =
                            \lambda \int\limits_{0}^{\infty} x^2 e^{-\lambda x} \dif x =
                            - \frac{1}{\lambda^2} = \frac{1}{\lambda^2} . 
                    \end{equation*}

                    Показательное распределение тесно связано с простейшим (стационарным пуассоновским) потоком событий:
                    
                    Интервал времени $T$ между двумя соседними событиями в простейшем потоке
                    имеет показательное распределение с параметром, равным интенсивности потока.

                    Функция распределения случайной величины $T$ --- интервала времени между двумя соседними событиями в потоке:
                    %
                    \begin{equation*}
                        F(t) = P(T < t) .
                    \end{equation*}

                    Рассмотрим на оси $Ot$ интервал времени $T$ между двумя соседними событиями:

                    \begin{tikzpicture}
                        \draw [{<[length=12pt, width=6pt]}-{>[length=12pt, width=6pt]}]
                            (2, 1) --
                            (8, 1) node [above, midway] {$t$};
                        \draw [{<[length=12pt, width=6pt]}-{>[length=12pt, width=6pt]}]
                            (2, -1) --
                            (6, -1) node [below, midway] {$T$};
                        \fill[fill=Medium!40!white, opacity=0.3]
                            (2, 0)
                            rectangle (8, 0.6);
                        \fill[fill=Medium, opacity=0.3]
                            (2, 0)
                            rectangle (6, -0.6);
                        \draw [-{>[length=12pt, width=6pt]}, darkgray, thick]
                            (-0.8, 0) --
                            (10, 0);
                        \node [darkgray, anchor=north east]
                            at (10, -0.2) {$t$};
                        \draw [darkgray, thick]
                            (0, -0.2) node [below] {$0$} --
                            (0, 0.2);
                        \draw
                            (2, -1.2) --
                            (2, 1.2);
                        \draw
                            (8, 0) --
                            (8, 1.2);
                        \draw
                            (6, -1.2) --
                            (6, 0);
                    \end{tikzpicture}

                    Для того, чтобы выполнилось неравенство $T < t$, необходимо, чтобы на хотя бы одно событие потока попало на участок длины $t$. Вероятность этого
                    %
                    \begin{equation*}
                        P(T < t) = P_t (k \sgeq 1) = 1 - P_t (k = 0) = 1 - e^{-\lambda t} .
                    \end{equation*}

                    Таким образом,
                    %
                    \begin{equation*}
                        F(t) = 1 - e^{-\lambda t} ,
                    \end{equation*}
                    %
                    а плотность распределения
                    %
                    \begin{equation*}
                        f(t) = \lambda e^{-\lambda t} ,
                    \end{equation*}
                    %
                    то есть случайная величина имеет показательное распределение.

                \paragraph{Нормальное распределение, или закон Гаусса}

                    Непрерывная случайная величина $X$ имеет нормальное распределение, если её плотность вероятности имеет вид
                    %
                    \begin{equation*}
                        f(x) = \frac{1}{\sigma \sqrtt{2 \pi}} \,
                            e^{-\frac{(x - m)^\text{\tiny 2}}{2 \sigma^\text{\tiny 2}}} =
                            \frac{1}{\sigma \sqrtt{2 \pi}} \,
                             \expo \! \bigg( \! -\frac{(x - m)^2}{2 \sigma^2} \bigg) .
                    \end{equation*}

                    Кривая нормального распределения:

                    \begin{tikzpicture}
                        \def\m{0.7}
                        \begin{axis}[samples=100, tick label style={font=\footnotesize}, xtick={0, \m}, xticklabels={0, $m$}, ytick={0}]
                            \draw [thin, dotted]
                                (\m, 0) -- (\m, 2);
                            \addplot [Medium!40!white, thick, domain=-2+\m:2+\m]
                                {2 * e^(-((2 * (x - 0.7))^2))};
                            \addplot [Medium, thick, domain=-2+\m:2+\m]
                                {e^(-((x - 0.7)^2))};
                            \node [Medium!40!white, anchor=south west]
                                at (1.05, 1.3) {$\sigma$};
                            \node [Medium, anchor=south west]
                                at (1.5, 0.53) {$2 \sigma$};
                        \end{axis}
                    \end{tikzpicture}

                    Определим числовые характеристики нормально распределённой случайной величины $X$.
                    
                    Математическое ожидание
                    %
                    \begin{equation*}
                        M[X] = \frac{1}{\sigma \sqrtt{2 \pi}}
                            \int\limits_{-\infty}^{+\infty} (x - m)^2 \cdot
                             \expo \! \bigg( \! -\frac{(x - m)^2}{2 \sigma^2} \bigg) \dif x .
                    \end{equation*}

                    Применив замену переменной
                    %
                    \begin{equation*}
                        t = \frac{x - m}{\sigma \sqrtt{s}} ,
                    \end{equation*}
                    %
                    получим
                    %
                    \begin{equation*}
                        M[X] = \frac{1}{\sqrtt{\pi}}
                            \int\limits_{-\infty}^{+\infty} (\sigma t \sqrtt{2} + m)
                            e^{-t^2} \dif t =
                            \frac{\sigma \sqrtt{2}}{\sqrtt{\pi}}
                            \int\limits_{-\infty}^{+\infty} t e^{-t^2} \dif t +
                            \frac{m}{\sqrtt{\pi}}
                            \int\limits_{-\infty}^{+\infty} e^{-t^2} \dif t .
                    \end{equation*}

                    В полученном выражении первый интеграл равен нулю (интеграл в симметричных пределах от нечётной функции), а второй интеграл есть интеграл Эйлера--Пуассона
                    %
                    \begin{equation*}
                        \int\limits_{-\infty}^{+\infty} e^{-t^2} \dif t =
                        2 \int\limits_{0}^{\infty} e^{-t^2} \dif t = \sqrtt{\pi} .
                    \end{equation*}

                    Таким образом, математическое ожидание величины $X$ равно $m$:
                    %
                    \begin{equation*}
                        M[X] = m .
                    \end{equation*}

                    Вычислим дисперсию случайной величины $X$:
                    %
                    \begin{equation*}
                        D[X] = \frac{1}{\sigma \sqrtt{2 \pi}}
                        \int\limits_{-\infty}^{+\infty} (x - m)^2 \cdot
                             \expo \! \bigg( \! -\frac{(x - m)^2}{2 \sigma^2} \bigg) \dif x .
                    \end{equation*}

                    Применив замену переменной
                    %
                    \begin{equation*}
                        t = \frac{x - m}{\sigma \sqrtt{s}} ,
                    \end{equation*}
                    %
                    получим
                    %
                    \begin{equation*}
                        D[X] = \frac{\sigma^2}{\sqrtt{\pi}}
                            \int\limits_{-\infty}^{+\infty} 2 t^2 e^{-t^2} \dif t .
                    \end{equation*}

                    Интегрируя по частям, получим
                    %
                    \begin{equation*}
                        D[X] = \frac{\sigma^2}{\sqrtt{\pi}}
                            \int\limits_{-\infty}^{+\infty} 2 t^2 e^{-t^2} \dif t =
                            \frac{\sigma^2}{\sqrtt{\pi}}
                            \bigg( -t e^{-t} \big|_{-\infty}^{+\infty} +
                            \int\limits_{-\infty}^{+\infty} e^{-t^2} \dif t \bigg) .
                    \end{equation*}

                    Первое слагаемое равно нулю ($e^{-t^2}$ при $t \to \infty$ убывает быстрее, чем возрастает любая степень $t$), второе слагаемое равно $\sqrtt{\pi}$, откуда
                    %
                    \begin{equation*}
                        D[X] = \sigma^2 .
                    \end{equation*}

                    Таким образом, нормальное распределение случайной величины полностью описывается двумя числовыми характеристиками: математическим ожиданием $m$ и средним квадратичным отклонением $\sigma$.

                    Рассмотрим влияние параметров $m$ и $\sigma$ на кривую распределения.
                    
                    При изменении параметра $m$ кривая $f(x)$, не изменяя формы, будет смещаться вдоль оси абсцисс.
                    
                    Изменение $\sigma$ равносильно изменению масштаба кривой по обеим осям. Например, при удвоении $\sigma$ масштаб по оси абсцисс удвоится, а по оси ординат уменьшится в два раза.

                    Центральные моменты нечётной степени для нормально распределённой случайной величины определяются равны нулю.
                    
                    Для вычисления центральных моментов чётной степени используется рекуррентное соотношение вида
                    %
                    \begin{equation*}
                        \mu_s = (s - 1) \, \sigma^2 \mu_{s - 2} .
                    \end{equation*}

                    Определим вероятность попадания нормально распределённой случайной величины $X$ в интервал от $\alpha$ до $\beta$:
                    %
                    \begin{equation*}
                        P(\alpha \sleq X < \beta) = \frac{1}{\sigma \sqrtt{2 \pi}}
                            \int\limits_{\alpha}^{\beta}  \expo \! \bigg( \!
                            -\frac{(x - m)^2}{2 \sigma^2} \bigg) \dif x .
                    \end{equation*}

                    Применив замену переменной
                    %
                    \begin{equation*}
                        t = \frac{x - m}{\sigma} ,
                    \end{equation*}
                    %
                    получим
                    %
                    \begin{equation*}
                        P(\alpha \sleq X < \beta) = \frac{1}{\sqrtt{2 \pi}}
                            \int\limits_{\frac{\alpha - m}{\sigma}}^{\frac{\beta - m}{\sigma}}
                            e^{-\frac{t^\text{\tiny 2}}{2}} \dif t .
                    \end{equation*}

                    Так как первообразная для $e^x$ не выражается через элементарные функции, то для вычисления вероятностей событий, связанных с нормальными случайными величинами, используют табулированную \key{функцию Лапласа}
                    %
                    \begin{equation*}
                        \Phi (x) = \frac{1}{\sqrtt{2 \pi}}
                            \int\limits_{0}^{\infty} e^{-\frac{t^\text{\tiny 2}}{2}} \dif t .
                    \end{equation*}

                    С помощью этой функции вероятность попадания нормально распределённой случайной величины $X$ на интервал от $\alpha$ до $\beta$ определится так:
                    %
                    \begin{equation*}
                        P(\alpha \sleq X < \beta) =
                            \Phi \Big( \frac{\beta - m}{\sigma} \Big) -
                            \Phi \Big( \frac{\alpha - m}{\sigma} \Big) .
                    \end{equation*}

                    Функция Лапласа обладает следующими свойствами:
                    \begin{enumerate}
                        \item $\Phi (0) = 0$.
                        \item $\Phi (-x) = -\Phi (x)$.
                        \item $\Phi (-\infty) = 0,5$.
                    \end{enumerate}

                    Функция распределения нормально распределённой случайной величины через функцию Лапласа выражается так:
                    %
                    \begin{equation*}
                        F(x) = 0,5 + \Phi \Big( \frac{x - m}{\sigma} \Big) .
                    \end{equation*}

                    Таблицы значений функции $\Phi (x)$ даны в приложениях к учебникам по теории вероятностей.

                    Нормально распределённая случайная величина возникает в тех случаях, когда складывается много независимых (или слабо зависимых) случайных величин $X_1 , \: X_2 , \: \ldots , \: X_n$.
                    
                    Тогда, каковы бы ни были законы распределения отдельных случайных величин $X_i$, закон распределения их суммы будет близок к нормальному распределению.
                    
                    В частности, ошибки измерений распределяются по закону, близкому к нормальному.

        \newpage
        
        \subsection{Системы случайных величин}

            \subsubsection{Понятие системы случайных величин}

                \key{Система случайных величин}, или \key{случайный вектор}, или \key{многомерная случайная величина} --- любая упорядоченная совокупность случайных величин $X = \{ X_1 , \: X_2 , \: \ldots , \: X_n \}$.

                Случайные величины $\{ X_1 , \: X_2 , \: \ldots , \: X_n \}$, входящие в систему могут быть как непрерывными, так и дискретными.
                
                Для наглядности рассмотрения пользуются геометрической интерпретацией:
                
                Систему двух случайных величин $\{ X, \: Y \}$ можно представить случайной точкой на плоскости с координатами $X$ и $Y$ или случайным вектором, направленным из начала координат в точку $(X, \: Y)$.
                
                Свойства случайных величин не исчерпываются свойствами отдельных величин, входящих в систему. Для описания характеристик систем случайных величин необходимы отдельные свойства.
                
                Рассмотрим эти свойства для $n$-мерного и двумерного случаев.

            \subsubsection{Функция распределения системы случайных величин}

                \key{Функция распределения}, или \key{совместная функция распределения} системы случайных величин --- вероятность совместного выполнения неравенств $X_1 < x_1 ; \: \ldots , \: X_n < x_n$:
                %
                \begin{equation*}
                    F(x_1 , \: \ldots , \: x_n) =
                        P \big( (X_1 < x_1) \cap \ldots \cap (X_n < x_n) \big) .
                \end{equation*}

                Для случая \key{двумерной случайной величины}
                %
                \begin{equation*}
                    F(x, \: y) = P \big( (X < x) \cap (Y < y) \big) .
                \end{equation*}

                Геометрически функция распределения $F(x, \: y)$ --- это вероятность попадания случайной точки $(X, \: Y)$ в бесконечный квадрант с вершиной в точке $(x, \: y)$, лежащей левее и ниже её:

                \begin{tikzpicture}
                    \begin{axis}[tick label style={font=\footnotesize}, xtick={0, 1}, xticklabels={0, $x$}, ytick={0, 1}, yticklabels={0, $y$}, xmin=-1, xmax=2, ymin=-1, ymax=2]
                        \addplot+ [name path=A, Medium, thick, domain=-1:1, no marks]
                            {1};
                        \path [name path=B]
                            (\pgfkeysvalueof{/pgfplots/xmin}, \pgfkeysvalueof{/pgfplots/ymin}) --
                            (\pgfkeysvalueof{/pgfplots/xmax}, \pgfkeysvalueof{/pgfplots/ymin});
                        \addplot [Light, fill opacity=0.15]
                            fill between [of=A and B, soft clip={domain=-1:1}];
                        \draw [Medium, thick]
                            (1, -1) -- (1, 1);
                        \fill [Medium, fill=Medium]
                            (1, 1) circle (2pt)
                            node [anchor=south west] {$(x, \: y)$};
                    \end{axis}
                \end{tikzpicture}

                \paragraph{Свойства функции распределения}

                    \begin{enumerate}
                        \item Значения функции распределения удовлетворяют двойному неравенству
                        %
                        \begin{equation*}
                            \begin{aligned}
                                & 0 \sleq F(x_1 , \: \ldots , \: x_n) \sleq 1 , \\[1.0ex]
                                & 0 \sleq F(x, \: y) \sleq 1 .
                            \end{aligned}
                        \end{equation*}

                        \prooff
                        Вытекает из определения функции распределения как вероятности: вероятность есть неотрицательное число, не превышающее 1. \qedd

                        \item Функция распределения $F(x_1 , \: \ldots , \: x_n)$ --- неубывающая по каждому из аргументов, то есть
                        %
                        \begin{equation*}
                            \begin{aligned}
                                x_i ' < x_i '' \: & \Rightarrow \: F(x_1 , \: \ldots , \:
                                    x_i ' , \: \ldots , \: x_n) \sleq F(x_1 , \: \ldots , \:
                                    x_i '' , \: \ldots , \: x_n) , \\[1.0ex]
                                x_1 < x_2 \: & \Rightarrow \: F(x_1 , \: y) \sleq
                                    F(x_2 , \: y) , \\[1.0ex]
                                y_1 < y_2 \: & \Rightarrow \: F(x , \: y_1) \sleq
                                    F(x , \: y_2) .
                            \end{aligned}
                        \end{equation*}

                        \prooff
                        Рассмотрим для случая двумерной случайной величины.
                        
                        При увеличении какого-нибудь из аргументов $(x, \: y)$ квадрант, заштрихованный на рисунке, увеличивается.
                        
                        Следовательно, вероятность попадания в него случайной точки $(X, \: Y)$ уменьшаться не может. \qedd

                        \item Если хотя бы один из аргументов функции распределения обращается в $-\infty$, то функция распределения равна $0$:
                        %
                        \begin{equation*}
                            \begin{aligned}
                                & F(x_1 , \: \ldots , \: -\infty , \: \ldots , x_n) = 0 , \\[1.0ex]
                                & F(-\infty , \: y) = 0 , \\[1.0ex]
                                & F(x , \: -\infty) = 0 .
                            \end{aligned}
                        \end{equation*}

                        \prooff
                        По определению функции распределения,
                        %
                        \begin{equation*}
                            \begin{aligned}
                                & F(x_1 , \: \ldots , \: -\infty , \: \ldots , \: x_n) = \\[1.0ex]
                                & \qquad P \big( (X_1 < x_1) \cap \ldots \cap
                                    (X_i < -\infty) \cap \ldots \cap (X_n < x_n) \big) .
                            \end{aligned}
                        \end{equation*}

                        Событие $\big( (X_1 < x_1) \cap \ldots \cap (X_i < -\infty) \cap \ldots \cap (X_n < x_n) \big)$ --- невозможное событие, так как невозможным является событие $(X_i < -\infty)$. Тогда
                        %
                        \begin{equation*}
                            F(x_1 , \: \ldots , \: -\infty , \: \ldots , \: x_n) = 0 . \qedd
                        \end{equation*}

                        \item Если все аргументы функции распределения $F(x_1 , \: \ldots , \: x_n)$ равны $+\infty$, то функция распределения равна 1:
                        %
                        \begin{equation*}
                            F(+\infty , \: +\infty , \: +\infty) = 1 .
                        \end{equation*}

                        \prooff
                        Следует из определения функции распределения системы случайных величин:
                        %
                        \begin{equation*}
                            \lim\limits_{\substack{x_1 \to +\infty\\\cdots\\x_n \to +\infty}}
                                F(x_1 , \: \ldots , \: x_n) = P \big( (X_1 < +\infty) \cap
                                \ldots \cap (X_n < +\infty) \big) = 1. \qedd
                        \end{equation*}

                        \item Если один из аргументов обращается в $+\infty$, то функция распределения $F(x_1 , \: \ldots , \: x_n)$ становится равной функции распределения $n - 1$ случайной величины:
                        %
                        \begin{equation*}
                            \begin{aligned}
                                & F(x_1 , \: \ldots , \: +\infty , \: \ldots , \: x_n) =
                                    F(x_1 , \: \ldots , \: x_{i - 1} , \: x_{i + 1} , \:
                                    \ldots , \: x_n) , \\[1.0ex]
                                & F(+\infty , \: y) = F(y) , \\[1.0ex]
                                & F(x , \: +\infty) = F(x) .
                            \end{aligned}
                        \end{equation*}

                        \prooff
                        По определению функции распределения,
                        %
                        \begin{equation*}
                            \begin{aligned}
                                & F(x_1 , \: \ldots , \: +\infty , \: \ldots , \: x_n) = \\[1.0ex]
                                & \qquad P \big( (X_1 < x_1) \cap \ldots \cap
                                    (X_i < +\infty) \cap \ldots \cap (X_n < x_n) \big).
                            \end{aligned}
                        \end{equation*}

                        Событие $(X_i < +\infty)$ является достоверным событием. Тогда
                        %
                        \begin{equation*}
                            \begin{aligned}
                                & P \big( (X_1 < x_1) \cap \ldots \cap (X_i < +\infty) \cap
                                \ldots \cap (X_n < x_n) \big) = \\[1.0ex]
                                & \qquad P \big( (X_1 < x_1) \cap \ldots \cap (X_n < x_n)
                                    \big) = \\[1.0ex]
                                & \qquad F(x_1 , \: \ldots , \: x_{i - 1} , \: x_{i + 1} , \:
                                    \ldots , \: x_n) .
                            \end{aligned} \qedd*{-4.3ex}
                        \end{equation*}

                        \item Вероятность попадания в прямоугольную область
                        %
                        \begin{equation*}
                            \begin{aligned}
                                & P(\alpha \sleq X \sleq \beta ; \:
                                    \gamma \sleq Y \sleq \delta) = \\[1.0ex]
                                & \qquad F(\beta , \: \delta) - F(\beta , \: \gamma) - 
                                    F(\alpha , \: \delta) + F(\alpha , \: \gamma) :
                            \end{aligned}
                        \end{equation*}

                        \begin{tikzpicture}
                            \begin{axis}[tick label style={font=\footnotesize}, xtick={1, 2}, xticklabels={$\alpha$, $\beta$}, ytick={1, 2}, yticklabels={$\gamma$, $\delta$}, xmin=0.25, xmax=2.6, ymin=0.25, ymax=2.6]
                                \addplot+ [name path=A, Medium, thick, domain=1:2, no marks]
                                    {1};
                                \addplot+ [name path=B, Medium, thick, domain=1:2, no marks]
                                    {2};
                                \addplot [Light, fill opacity=0.15]
                                    fill between [of=A and B, soft clip={domain=1:2}];
                                \draw [Medium, thick]
                                    (1, 1) -- (1, 2);
                                \draw [Medium, thick]
                                    (2, 1) -- (2, 2);
                                \draw [Medium, thick, dotted]
                                    (0.25, 1) -- (1, 1);
                                \draw [Medium, thick, dotted]
                                    (0.25, 2) -- (1, 2);
                                \draw [Medium, thick, dotted]
                                    (1, 0.25) -- (1, 1);
                                \draw [Medium, thick, dotted]
                                    (2, 0.25) -- (2, 1);
                                \fill [Medium, fill=Medium]
                                    (1, 1) circle (1.6pt)
                                    node [anchor=north east] {$\scriptstyle(\alpha, \: \gamma)$};
                                \fill [Medium, fill=Medium]
                                    (1, 2) circle (1.6pt)
                                    node [anchor=south east] {$\scriptstyle(\alpha, \: \delta)$};
                                \fill [Medium, fill=Medium]
                                    (2, 2) circle (1.6pt)
                                    node [anchor=south west] {$\scriptstyle(\beta, \: \delta)$};
                                \fill [Medium, fill=Medium]
                                    (2, 1) circle (1.6pt)
                                    node [anchor=north west] {$\scriptstyle(\beta, \: \gamma)$};
                                \node [Medium] at (1.5, 1.5) {$R$};
                            \end{axis}
                        \end{tikzpicture}
                        
                        Вероятность попадания в прямоугольник $R$ равна вероятности попадания в квадрант с вершиной в точке $(\beta , \: \delta)$ минус вероятность попадания в квадрант с вершиной в точке $(\beta , \: \gamma)$ минус вероятность попадания в квадрант с вершиной в точке $(\alpha , \: \delta)$ плюс вероятность попадания в квадрант с вершиной в точке $(\alpha , \: \gamma)$, которую мы вычли дважды.
                    \end{enumerate}

            \subsubsection{Система двух дискретных случайных величин. Матрица вероятности}

            \subsubsection{Система двух непрерывных случайных величин. Совместная плотность вероятности}

            \subsubsection{Многомерные непрерывные случайные величины}

            \subsubsection{Зависимые и независимые двумерные случайные величины}

            \subsubsection{Системы зависимых случайных величин}

\end{document}